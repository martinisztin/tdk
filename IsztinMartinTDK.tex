% LaTeX mintafájl szakdolgozat és diplomamunkáknak az
% SZTE Informatikai Tanszekcsoportja által megkövetelt
% formai követelményeinek megvalósításához
% Modositva: 2011.04.28 Nemeth L. Zoltan
% A fájl használatához szükséges a magyar.ldf 2005/05/12 v1.5-ös vagy késõbbi verziója
% ez letölthetõ a http://www.math.bme.hu/latex/ weblapról, a magyar nyelvû szedéshez
% Hasznos információk, linekek, LaTeX leirasok a www.latex.lap.hu weboldalon vannak.
%


\documentclass[12pt]{report}

\usepackage{url}
\usepackage{listings}
\lstset{captionpos=b}

\usepackage{setspace}

\usepackage[bottom]{footmisc}

%Magyar nyelvi támogatás (Babel 3.7 vagy késõbbi kell!)
\def\magyarOptions{defaults=hu-min}
\usepackage[magyar]{babel}

%Az ékezetes betûk használatához:
\usepackage{t1enc}% ékezetes szavak automatikus elválasztásához
\usepackage[latin2]{inputenc}% ékezetes szavak beviteléhez

% A formai kovetelmenyekben megkövetelt Times betûtípus hasznalata:
\usepackage{times}


\usepackage{setspace} % For controlling line spacing

%Az AMS csomagjai
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

%A fejléc láblécek kialakításához:
\usepackage{fancyhdr}

% definecolor
\usepackage{xcolor}

%Természetesen további csomagok is használhatók,
%például ábrák beillesztéséhez a graphix és a psfrag,
%ha nincs rájuk szükség természetesen kihagyhatók.
\usepackage{graphicx}
\usepackage{psfrag}

%Tételszerû környezetek definiálhatók, ezek most fejezetenkent egyutt szamozodnak, pl.
\newtheorem{tét}{Tétel}[chapter]
\newtheorem{defi}[tét]{Definíció}
\newtheorem{lemma}[tét]{Lemma}
\newtheorem{áll}[tét]{Állítás}
\newtheorem{köv}[tét]{Következmény}

%Ha a megjegyzések és a példak szövegét nem akarjuk dõlten szedni, akkor
%az alábbi parancs után kell õket definiální:
\theoremstyle{definition}
\newtheorem{megj}[tét]{Megjegyzés}
\newtheorem{pld}[tét]{Példa}

%Margók:
\hoffset -1in
\voffset -1.5in
\oddsidemargin 35mm
\textwidth 150mm
\topmargin 15mm
\headheight 10mm
\headsep 5mm
\textheight 237mm

% bolondba
\linespread{1.5}
%\setstretch{1.5}
\sloppy

% Kódrészletes színezése
\input{listings_def}
\renewcommand{\lstlistingname}{Kódrészlet}


\begin{document}

%A FEJEZETEK KEZDÕOLDALAINAK FEJ ES LÁBLÉCE:
%a plain oldalstílust kell átdefiniálni, hogy ott ne legyen fejléc:
\fancypagestyle{plain}{%
%ez mindent töröl:
\fancyhf{}
% a láblécbe jobboldalra kerüljön az oldalszám:
\fancyfoot[R]{\thepage}
%elválasztó vonal sem kell:
\renewcommand{\headrulewidth}{0pt}
}

%A TÖBBI OLDAL FEJ ÉS LÁBLÉCE:
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Sérülékenységet tanúsító egységtesztek automatikus generálásának vizsgálata}
\fancyfoot[R]{\thepage}


%A címoldalra se fej- se lábléc nem kell:
\thispagestyle{empty}

\begin{center}
\begin{singlespace}
%\vspace*{1cm}
{\Large\bf Szegedi Tudományegyetem}

\vspace{0.5cm}

{\Large\bf Informatikai Intézet}

\vspace*{3cm}


{\LARGE\bf Sérülékenységet tanúsító egységtesztek}\\
\vspace{2mm}
{\LARGE\bf automatikus generálásának vizsgálata}


\vspace*{2.6cm}

{\Large TDK dolgozat}
% vagy {\Large Szakdolgozat}

\vspace*{2cm}

%Értelemszerûen megváltoztatandó:
%{\large
%\begin{tabular}{c@{\hspace{2cm}}c}
%\emph{Készítette:} &\emph{Témavezetõk:}\\
%\bf{Isztin Martin} &\begin{tabular}{@{\hspace{0.5cm}}c@{\hspace{1.5cm}}c}\bf{Dr. Antal Gábor} &\bf{Dr. Bán Dénes}\\\end{tabular}\\
%programtervezõ informatikus &\begin{tabular}{@{\hspace{3cm}}c@{\hspace{1.5cm}}c@{\hspace{1cm}}}adjunktus  &tudományos munkatárs\\\end{tabular}\\	
%\end{tabular}
%}

{\large
\noindent
\emph{Készítette:}\\
{\bf Isztin Martin}\\
{\textit {programtervezõ informatikus}}\\
\vspace{0.1cm}
{\textit {III. évf. BSc hallgató}}
}

\vspace*{1.5cm}

{\large
\noindent
\emph{Témavezetõk:}\\
{\bf Dr. Antal Gábor}\\
{\textit {adjunktus}}\\
}

\vspace*{0.3cm}

{\large
\noindent
{\bf Dr. Bán Dénes}\\
{\textit {tudományos munkatárs}}\\
}

\vspace*{2.3cm}

{\Large
Szeged
\\
\vspace{2mm}
2024
}
\end{singlespace}
\end{center}


%A tartalomjegyzék:
\tableofcontents

%A \chapter* parancs nem ad a fejezetnek sorszámot
\chapter*{Absztrakt}
%A tartalomjegyzékben mégis szerepeltetni kell, mint szakasz(section) szerepeljen:
\addcontentsline{toc}{section}{Absztrakt}

\begin{spacing}{1.4}
Egy szoftver fejlesztésének életciklusában fontos minõségbiztosítási szerepet játszik a tesztelés. 
Megfelelõ tesztekkel a kód lefedettségének növelésén és a regressziók elkerülésén felül arról is megbizonyosodhatunk, 
hogy egy esetleges sérülékenység jelen van-e a szoftverünkben - és hogy azt egy potenciális javítás valóban javítja-e. 
Ám az ilyen tesztek elkészítése bonyolult, költséges és manuális folyamat.

Hogy segítsük mind a tesztelõk, mind a biztonsági szakértõk munkáját, ebben a dolgozatban az egyik legelterjedtebb nyelvi modell, 
a ChatGPT automatikus egységteszt generálási képességét kutatjuk a sérülékenységek szemszögébõl. 
A VUL4J nevezetû, tanúsított CWE sebezhetõségekkel és hozzájuk tartozó javításokkal rendelkezõ Java projektgyûjtemény egy részhalmazán vizsgáljuk, 
hogy a GPT képes-e a javítás elõtti és utáni kódállapot együttes ismeretében szintaktikailag és/vagy szemantikailag  helyes egységteszteket generálni az adott sérülékenység kivédésének bizonyítékaként. 
Figyelmet fordítunk ezen belül a kódkontextus bõségének hatására, a GPT ön-hibajavítási képességének hatékonyságára és a generált tesztesetek szubjektív hasznosíthatóságára.

Eredményeink azt mutatják, hogy a GPT domain-specifikus elõtanítás nélkül is szintaktikailag korrekt teszteseteket generál az esetek 50\%-ában. 
És habár a javítások szemantikai helyessége csak az esetek 15\%-ban volt automatikusan validálható, szubjektív kiértékelésünk alapján a GPT az esetek többségében olyan teszt sablont generál, 
ami minimális emberi finomhangolással teljes értékû sérülékenység igazolássá fejleszthetõ tovább. 
Tehát a kis mennyiségû rendelkezésre álló adat ellenére már ezek a korai eredmények is arra engednek következtetni, 
hogy a GPT sikerrel használható a sérülékenység-tesztelésben - ha nem is teljesen autonóm módon, de egy intelligens támogatói folyamat részeként mindenképp.	

%\vspace{12pt}
{\bf Kulcsszavak:} generált egységtesztek, nyelvi modell, sérülékenység, CWE, kontextus szintek
\end{spacing}



%\chapter*{Tartalmi összefoglaló}
%\addcontentsline{toc}{section}{Tartalmi összefoglaló}

%A tartalmi összefoglalónak tartalmaznia kell (rövid, legfeljebb egy oldalas, összefüggõ megfogalmazásban)
%a következõket: a téma megnevezése, a megadott feladat megfogalmazása - a feladatkiíráshoz viszonyítva-,
%a megoldási mód, az alkalmazott eszközök, módszerek, az elért eredmények, kulcsszavak (4-6 darab).

%Az összefoglaló nyelvének meg kell egyeznie a dolgozat nyelvével. Ha a dolgozat idegen nyelven készül,
%magyar nyelvû tartalmi összefoglaló készítése is kötelezõ (külön lapon), melynek terjedelmét a TVSZ szabályozza.

%\chapter*{Bevezetés}
\chapter{Bevezetés}
%\addcontentsline{toc}{section}{Bevezetés}

A mai napig rengeteg olyan szoftver lát napvilágot a fogyasztói világban, amelyben sérülékenységek találhatók. Ezek mindaddig észrevétlenek maradnak, amíg valaki ki nem használja õket.
Sajnos nem elég csupán szemmel ellenõrizni egy programkód hitelességét egy tapasztalt személynek sem, mivel akár olyan kódrészlet is okozhat sebezhetõséget, amely egy másik környezetben teljesen ártalmatlan.
Az ilyen hibák kijavítása rengeteg idõ és pénzügyi áldozattal jár. Egy szoftverben rejlõ sebezhetõségek szerencsére hamar észrevehetõk és kiküszöbölhetõk megfelelõ mértékû teszteléssel, azonban ezeknek a megírása 
szintén erõforrásigényes feladat.


Léteznek olyan adatbázisok, amelyek gyakori nyilvánosságra hozott sérülékenységeket dokumentálnak. 
A CVE (\textit{Common Vulnerabilities and Exposures})~\cite{cve} valós rendszerek kiberbiztonsági sérülékenységeirõl tartalmaz információkat. Az itt található bejegyzésekhez
társul egy azonosító is, amely egy adott sérülékenységet reprezentál. Ezen sérülékenységek általánosabb kategorizálása a CWE (\textit{Common Weakness Enumeration})~\cite{cwe} azonosítókkal történik.

A mára már szinte bárkinek elérhetõ nagy nyelvi modellek széleskörûen elterjedtek produktivitásnövelõ technológiaként és a modellek által nyújtott lehetõségek miatt 
a szoftverfejlesztés számos területén szintén használják.
Számos kutatás számol be a feltörekvõ technológia automatikus programjavító képességeirõl, viszont az ezt próbáratevõ egységtesztek generálásáról kevés információt tudunk.

% ide mondjuk vul4j átvezetés
A dolgozat célja a gyakorlatban felismert sebezhetõségekhez való egységteszt generálás, ezért a kiértékelés során a VUL4J~\cite{vul4j} projektgyûjtemény részhalmazát használtuk, amely számos Java nyelven íródott valós rendszer sérülékenységeirõl
tartalmaz információkat, többek között a sérülékenység javítását, a sérülékenységhez tartozó CVE és többnyire CWE azonosítót.
További elõnyei az adathalmaznak, hogy a biztosított környezettel könnyedén lehet alternálni a sérülékeny és javított változatai között a projekteknek, 
elérhetõk a sérülékenység javításával alkalmazott változtatások és a projektben eredetileg használt egységtesztek is. 

A kiértékeléshez használt részhalmazunk 20 olyan példát tartalmaz, amelyet igyekeztünk úgy kiválasztani, hogy minél több sérülékenység fajtát lefedjen.
Minden példát fokális kontextusokra bontottunk~\cite{focal_context}, amely négy szintbõl állt (0-3).
A kutatás során az egyik legismertebbek nyelvi modellt használtuk, az OpenAI cég generatív elõtanított traszformer modellje, a GPT-t, ezen belül is a legfrissebb GPT-4 Turbo változatát.
A promptoláshoz kizárólag egy szerepet és a rendelkezésre álló kódot adtuk át. 
Az eredmények osztályozása két részre különíthetõ. Elõször egy automatizált környezetben végeztük el a kontextus legyártását, promptolást, a kapott válasz feldolgozását és a kiértékelését, aztán kézzel is 
felülbíráltuk a generálások szubjektív használhatóságát.

A kutatás a következõ kérdésekre keresi a választ:

\begin{itemize}
\item RQ1: Hány százalékban volt forduló kód?
\item RQ2: Hány százalékban volt sikeres szintaktikai és szemantikai generálás?
\item RQ3: Hogyan befolyásolja a kontextus a generálás pontosságát?
\item RQ4: Milyen a szubjektív használhatósága a generált teszteknek?
\end{itemize}

Eredményeink azt mutatják, hogy a GPT domain-specifikus elõtanítás nélkül is szintaktikailag korrekt teszteseteket generál az esetek 50\%-ában, amely bíztató eredmény annak tudatában, hogy semmilyen
technikai háttérinformációt nem adtunk át a promptolás során. A tesztesetek szemantikai helyessége 15\%-ban volt automatikusan validálható, ennek ellenére a szubjektív, kézi kiértékelésünk során a GPT az esetek
többségében ez sokkal nagyobb arányban generált hasznos sablont a fejlesztõk számára.
Ez mutatja, hogy a nagy nyelvi modellek kellõ finomhangolással nagyon hasznos részét képezhetik ezen fontos munkafolyamatnak is.

A dolgozat felépítése a következõk szerint szervezõdik: a 2. fejezetben a témához kapcsolódó munkákról beszélünk, a 3. fejezet a kutatás módszertanát mutatja be. 
A kutatással elért eredményeket a 4. fejezetben részletezzük, utána a speciális esetekrõl ejtünk szót. 
A limitációkról és a jövõbeli lehetõségekrõl a 5. fejezetben számolunk be, végül a 6. fejezet zárja be a dolgozatot.


%-minden adat megvan ahhoz, hogy megnézzük jól tud e generálni unittestet a GPT (sebezhetõ metódus, patchelt metódus, különbözõ kontextus szintek, akár CWE is)

%-eredmények roughly

%-tdk felépítése, mire keresünk választ

%  RQ1: hány százalékban volt forduló kód?

%  RQ2: hány százalékban volt sikeres szintaktikai és szemantikai generálás?

%  RQ3: hogyan befolyásolja a context a pontosságot?

%  RQ4: szubjektív használhatósága a generált teszteknek



\chapter{Kapcsolódó munkák}

\section{Nagy nyelvi modellek a sérülékenység analízisben}

A nagy nyelvi modellek széleskörûen használtak a sérülékenység analízisben. A legjelentõsebb iránya az APR (Automated Program Repair), amirõl számos tanulmány szól.
Quanjun Zhang és társai összevetették a VRepair transzfer-tanuló neurális hálózati modell APR képességeit számos nagy nyelvi modellel~\cite{01}, köztük a CodeBERT-tel, UniXcoderrel és CodeGPT-vel.
Fõ eredményként fény derült a tényre, hogy a nagy nyelvi modellek 10.21\% és 22.23\% közti értékkel pontosabban hajtották végre a javításokat.

Egy másik tanulmány keretein belül Michael Fu és társai kifejezetten a ChatGPT-t használták a modell APR képességeinek felmérésére~\cite{02} a Big-Vul nevezetû adathalmazon, amely C++ nyelvben íródott  
projektek függvényeinek sérülékeny és javított változatait egyaránt tartalmazza, CVE, CWE azonosítókkal együtt, további egyéb technikai információkkal. A ChatGPT finomhangolások nélkül hátramarad a kódspecifikus
modellekkel szemben.

A GPT adottságain túl Kamel Alrashedy és társa a CodeLlama nevezetû modellt is megvizsgálta~\cite{05} egy Python sebezhetõségi adatbázissal, visszajelzés vezérelt hibajavítással, miszerint egy másik példánya 
a modellnek véleményezi az eredeti példány válaszát, majd ezen vélemény alapján történik az eredeti példány válaszának finomhangolása. Ezzel a megközelítéssel 5-10\%-kal jobb eredményeket értek el.

A témánkhoz releváns ötletként megemlíthetõ Chunqiu Steven Xia csapatának ötlete~\cite{11}, amelyben a generált hibajavítás helyességét megadott tesztekkel validálják.

A nagy nyelvi modellek ilyen módú alkalmazhatóságának fényében mi a sérülékenységek témakörét vesszük célba, és mi is a ChatGPT segítségével, 
de mi javítások automatizálása helyett már létezõ javítások helyességét szeretnénk ellenõrizni a hozzájuk tartozó tesztesetek generálása által.

\section{Nagy nyelvi modellek a teszteset generálásban}

Egy tanulmány statikus metrikákat alkalmazva finomhangolta a modelleket, a magas minõségû egységtesztek generálására~\cite{03}, miszerint egy alap modell 17\%-ban szintaktikailag hibás, 
31\%-ban állítás (assertion) nélküli tesztet generál és az esetek 37\%-ában nem hívja meg a tesztelendõ metódust. Az erõsítéses tanítás eredményeként felügyelt finomhangolással és az RLSQM 
(Reinforcement Learning from Static Quality Metrics) alkalmazása után ezek a számok lecsökkentek 1\%, 5\% és 10\% környéki értékekre. A finomhangolás során dinamikus kontextushosszt használtak, 
ami akár az egész fájl szövege volt, egy egész osztály, csak a metódus fejlécek, vagy csak a metódus maga.

Michele Tufano és csapata szintén különbözõ fokális kontextusszintekkel kísérleteztek az egységteszt generálás~\cite{focal_context} promptolása során. Ez a megközelítés sokkal hasonlóbb ahhoz az átadott dinamikus kontextushoz, 
amit mi választottunk. Kezdve kizárólag a fokális metódustól, hozzáadva szintenként az osztály nevét, a konstruktor fejléceit, a metódusok fejléceit és végül az osztály mezõit.
A használt modell tanítása progresszíven történt. Történt egy angol nyelvû elõtanítés, utána egy kódbázisú, végül egy teszteset generáláshoz kapcsolódó finomhangolás.
A generálás egy fordítási folyamatnak van értelmezve, fokális kontextusról tesztesetre.

Egy empirikus tanulmányban szintén új kutatási dimenziót képezett a kontextus hatása a teszt generálására vonatkozóan, habár itt a kontextus máshogy játszik szerepet. A különbözõ szinteket a Java dokumentáció 
jelenléte és specifikussága definiálta~\cite{06}. Három szintje a következõképp épült fel: Javadoc nélküli kontextus, részleges Javadoc (használati példák nélkül) és teljes Javadoc implementáció nélkül.
Az osztály, a javítást megelõzõ és a javított metódus mindig szerepel a bemenetben.
A generált tesztek 40-70\%-a nem okoz fordítási hibát, szubjektív kiértékelés során ez az arány sokkal nagyobb, 75-100\%. 50-80\%-ban helyes generálás történt és 70-90\% volt a kódlefedettség.
Egyéb érdekesség, hogy elõzetes munkálatok kimutatják, hogy a nagy nyelvi modellek jobban teljesítenek gyengén típusos nyelvek használata során.

Egy Meta cég által kiállított tanulmányban~\cite{07} nem generálnak konkrét "nyers" teszteket, hanem a már létezõ ember által írt teszteket próbálták feljavítani.
75\%-ban szintaktikailag helyes javítás történt, 57\%-ban átmenõ tesztet generált, a kód lefedettsége pedig 25\%-kal javult. Összesítésben a bemenetkét megadott teszt osztályok 10\%-át javította fel és 
a modell ajánlásai késõbb 73\%-ban elfogadottnak minõsültek a fejlesztõk által.

Alok Mathur és csapata olyan megközelítést alkalmazott a T5 és GPT-3 modellekkel, hogy kizárólag teszt bemeneteket generálnak és/vagy releváns természetes szöveges leírást~\cite{10}.
A fejlesztõk leírnak néhány peremfeltételt vagy követelményeket és a model kimenete releváns tesztesetek lesznek, amik kiértékelhetõk a rendszer megfelelõ végrehajtájtási útvonalaihoz.

Egy nagy nyelvi modellekkel való szoftvertesztelésre specializált kutatási felmérés~\cite{08} alapján senki se gondolkodott még az általunk használt irányban, bemeneti formátum szempontjából.
Kizárólag a hibás függvényt adják át, elõ- vagy utótagot, vagy leírást a javítás, vagy teszt generálásához, de senki sem próbálkozott mind a hibás és a javított kód átadásával a tesztgeneráláshoz. 
A Sugmin Kang és társai által kiállított tanulmányban~\cite{085} szereplõ bemeneti formátum a hiba leírását adja meg a teszteset generáláshoz.

Habár mi is teszt eseteket generálunk, a fentiekkel szemben a mi kutatásunk nem csak egy adott funkcionalitás tesztelését célozza a nagyobb lefedettség vagy a jobb olvashatóság érdekében, 
hanem egy adott sérülékenység elõtte/utána állapotai alapján próbál kimondottan a sérülékenységet bizonyító tesztesetet elõállítani, ami az sérülékeny állapoton hibát jelez, míg a javított változaton sikeresen lefut.



\section{Sérülékenységekhez tartozó tesztesetek}

A mi vizsgálatunkhoz leghasonlóbb irodalom a sérülékenységek és a tesztesetek metszetét tekinti.~\cite{09} az egységteszt generálás szintén úgy történik, hogy a bemenet tartalmazza a régi és új változatát a kódnak,
 de a tényleges generálás instrumentálás és útvonallefedettségen alapul.

TODO: 12 ???

A mi kutatásunk is ebben a metszetben helyezkedik el, de a fentiekkel szemben mi a napjainkban kibontakozó, 
és egyre biztatóbb eredményeket elérõ nagy nyelvi modelljeit használjuk a sérülékenység bizonyítékául szolgáló teszteset generálására az instrumentáció és/vagy genetikus algoritmusok alkalmazása helyett.


\chapter{Módszertan}
%\addcontentsline{toc}{section}{Módszertan}

A kutatásunk folyamata öt lépésre osztható. Elsõsorban kigyûjtöttünk 20 példát a kiértékeléshez, ezután a sérülékeny metódussal rendelkezõ osztályokat felbontottuk fokális kontextusszeletekre.
Létrehoztunk egy promptot, amelyekbe a kiértékelés során beleágyazódott a megfelelõ szintû kódkontextus. Lefuttattuk a többlépcsõs kiértékelõ szkriptet, végül manuálisan átvizsgáltuk a kiértékelés eredményeit. 

\section{Adatok kigyûjtése}
\label{sec:methodology-data}

A kiértékeléshez valós rendszerekben valaha fennálló sérülékenységeket gyûjtöttünk ki. 
Amire mindenképpen szükségünk volt az adathalmaz kiválasztása során, azok a sérülékeny metódusok és javításuk és egy környezet, amiben ezeket a metódusokat tesztelni tudjuk. 

Ezeknek az igényeknek eleget tett az APR-rel kapcsolatos kutatásokhoz széleskörben használt VUL4J~\cite{vul4j} adatbázis, amely számos tanúsított Java sérülékenységekhez tartalmaz valós példákat. 
Rengeteg hasznos információ áll rendelkezésünkre ezzel az adatbázissal, köztük az egyes projektekben szereplõ sérülékenységi azonosítók, javítás elõtti és utáni állapotok, GitHub commit hivatkozások és 
viszonyítási alapnak a PoV (proof of vulnerability) egységtesztek az egyes sérülékenységekhez. 
Társul hozzá egy Docker környezet is, amely nagyban megkönnyíti a projektek lefuttatását és ellenõrzését. 

Az adatbázisban szerepelnek olyan sebezhetõségek, amely kijavításához egy, vagy több metódus javítása szükséges, ami akár több osztály módosítását is igényelheti.
A modell kontextusból való kifutás veszélyének csökkentéseként úgy döntöttünk, hogy csak olyan példákat használunk a kiértékelés során, amelyekben a sérülékenység javítása csak egyetlen osztályt, metódust érint. 

Hogy minél szélesebb spektrumban mérhessük a GPT egységteszt generálási képességeit, igyekeztünk minél több, különbözõ sérülékenységgel rendelkezõ példát használni. 

\section{Fokális kontextusszintek és a promptolás}
\label{sec:methodology-focal-prompt}

Az egységteszt generálásához, a megfelelõ mértékû kontextus definiálása elengedhetetlen, a természetes szöveg mellé szükségünk van a tesztelendõ metódus mellékelésére.
Ehhez a kigyûjtött példák összes sebezhetõ osztályából kontextusdarabokat~\cite{focal_context} gyártottunk, amelyek segítségével az automatizált kiértékelés során könnyedén szabályozhattuk, hogy mekkora kontextussal szeretnénk az adott 
mérést elvégezni. 

Kisebb adathalmazokon való tesztelések után a szintek elosztásában a következõképp döntöttünk:
\begin{itemize}
\item \textbf{L0}: tartalmazza az osztály csomagdeklarációját, az osztály deklarációját és a sebezhetõ metódust.
\item \textbf{L1}: tartalmazza a \textbf{L0}-ban felsorolt elemeket és az osztály konstruktorainak fejlécét, ha van.
\item \textbf{L2}: tartalmazza a \textbf{L1}-ben felsorolt elemeket és az osztályban deklarált metódusainak fejlécét.
\item \textbf{L3}: tartalmazza a \textbf{L2}-ben felsorolt elemeket és az osztályban deklarált mezõket. 
\end{itemize}

A kiértékelés során minden szintbõl lezajlott egy futtatás.

Ahogy az elõbb is említettem, a generáláshoz megfelelõ méretû és elegendõen specifikus kontextusra van szükségünk. 
Elsõ lépésként promptolási referenciákat gyûjtöttünk elõzetes releváns szakirodalmakból~\cite{08,09}, majd a promptolással való kísérletezés következett.

Igyekeztünk minél optimálisabb és lényegretörõbb bemeneti szöveget definiálni, ezért a kísérleti futtatásokból kinyert tapasztalatok alapján formáltuk meg a végleges promptot.


A hivatalos OpenAI dokumentációja szerint\footnote{\url{https://platform.openai.com/docs/guides/gpt/chat-completions-api}} egy válasz generálása során, ha specifikálunk a GPT-nek saját szerepkört, 
akkor könnyebben megérti a hozzáadott kontextust, amivel szemben áll. Ellenkezõ esetben a generikus "segítõkész asszisztens" szerepet kapja meg.
Ez a mi promptunkban az átadott bemenet elejét képezi.
Ezek után ismertetjük a feldolgozandó bemenet jellemzõit, majd a feladatot, amin a modell dolgozni fog.

A leggyakrabban elõforduló hiba a GPT által generált egységtesztekben, az általa írt kódban használt függvények, osztályok importálásának hiánya.

A kiértékelésre szánt példák jelentõs része elavult Java verzióval kerültek fordításra, ezért többször is elõfordult, hogy olyan kódot generált a modell, ami nem volt kompatibilis ezekkel a változatokkal.
Ezért úgy döntöttünk, hogy külön figyelmeztetjük a modellt a promptolás során ezekre a részletekre.
Az osztály nevek egységessége is problémát okozott az automatikus kiértékelés során, ezért a kiértékelés során ezeknek a formátumát is definiáltuk a promptban.

Ezután következett maga a feldolgozandó bemenet, a forráskód az elõzõ fejezetben említett fokális kontextusként megadva. Elõször a sérülékenységgel rendelkezõ metódus, körítve a kontextusszintnek megfelelõ hozzáadott
adatokkal, ezt követõen pedig a javítást tartalmazó metódus, de ez már a kontextus többi része nélkül, annak érdekében, hogy a feldolgozandó prompt mérete ne legyen feleslegesen túl nagy.

Végezetül érzelmi stimulációt alkalmazunk a modellen, amiben közöljük, hogy a feladat megoldása nagyon fontos számunkra. Ez az eljárás jobb eredményekhez vezet.~\cite{erzelmi_stimulacio}

\newpage

A végsõ prompt, amellyel a kiértékelés összes példája lezajlott a következõképp állt össze:

\begin{lstlisting}[caption={A végleges prompt}, captionpos=b, breaklines=true]
  You are a senior software tester and a cyber security specialist.
  You will be given the source code of a Java class where you will find the context of a vulnerable method before and after the patch.
  Your task is to create a unit test that triggers the vulnerability and fails before the patch and passes after it. The class' name should be the name of the class appended with the string "Test".
  Use simple Java language features in the generated test!

  {focal context of the vulnerable code}

  The method after patching the vulnerability:

  {patched method of vulnerable code}

  It is very important for me, please create the unittest based on your best knowledge in the given context.

\end{lstlisting}

Az automatikus kiértékelés során felvetettük az ötletet, hogy érdemes lenne több iterációt végrehajtani a véletlenszerû eredmények elkerülése, a generálás konzisztenciájának vizsgálata érdekében.
Az iterációk helyett korlátozott számú visszakérdezéses finomhangolás mellett döntöttünk, abban az esetben, ha a generált válasz nem felel meg a megfelelõ szempontok alapján kiállított kritériumoknak.
Ezekhez a visszakérdezésekhez különbözõ promptok társulnak. Mivel a visszakérdezés ugyanabban az üzenetváltási környezetben történik, ezért a modell nem felejti el az elõzõlegesen átadott információkat, így 
ezeknél a promptoknál nem szükséges a szerepkör és egyéb technikai információ ismertetése.

Ebbõl kiindulva csupán egy egyszerû visszajelzést adtunk bemenetként a GPT-nek, az éppen fennálló kritérium megsértésérõl a tesztelés futtatása során keletkezett naplófájl társításával.

Három elfogadást megtagadó helyzet állt fent, amelyekhez társult prompt:

\begin{itemize}
  \item \textbf{BEFORE\_SUCCESS} - A sérülékeny metódus átmenõ tesztet produkál.
  \item \textbf{AFTER\_FAILURE} - A javított metódus nem átmenõ tesztet produkál.
  \item \textbf{ERROR} - A teszt futtatása fordítási hibát okoz.
\end{itemize}


\newpage


\section{Kiértékelõ környezet}
\label{sec:methodology-evalenv}

A kutatás során a legnagyobb szerepet az automatizált kiértékelõnk játszotta.
A generálás a GPT legújabb elérhetõ modelljével történt, a legfrissebb GPT-4 Turbo-t használtuk.
Nagyban megkönnyítette az adathalmazunkon végzett mérések folyamatát, hiszen a projektenként szétbontott kontextusszeletek és a projektek elérési útvonalának segítségével, a GPT API-val való kommunikáción át, 
a generált válasz lefuttatása és az eredmény kiértékelése teljesen automatikus volt. 
Ezen evaluálás egy néhány lépcsõs folyamatba foglalható.% A végleges változatunkban minden példa egyesével került feldolgozásra. 

\subsubsection{Kontextus legyártása}

Elsõsorban az elõre definiált fokális kontextusszint megadásával megépítette azt a Java fájlt, 
amely szintaktikailag is helyesen struktúrálva tartalmazta a szintnek megfelelõ mennyiségû adatot az adott sérülékenységrõl.

\subsubsection{Kommunikáció a GPT-vel}
A legyártott Java fájl került átadásra a GPT API-val kommunikáló komponensnek, amely a fentebb kifejtett promptot tette egésszé.
A modellel való kommunikáció során visszakapott válaszból kinyeri a Java kódot, amelyet elment egy fájlba és elhelyezi a projekt tesztkörnyezetébe.

\subsubsection{Futtatások}
A futtatás a VUL4J adatbázishoz járó Docker környezetet inicializálva, mindenféle fordításhoz szükséges kompatibilitási igényt kielégítve történik. 
A csökkentett futtatási idõ érdekében kizárólag azt a tesztet futtatja, amelyet a GPT generált.

A futtatás elõször a projekt sérülékenységgel rendelkezõ változatára fut le, és a tesztelés naplófájlját a szkript eltárolja és felhasználja az adott generálás kiértékelésére.
A sérülékeny változat tesztelésének befejezése után, ugyanez a folyamat lezajlott a javítással rendelkezõ változat esetén is.

Megvizsgálja, hogy az adott teszt sikeresen lefutott-e és amennyiben az aktuális állapotban (sérülékeny vagy javított) nem elvárt értéket kapunk, elkezdõdik a visszakérdezéses generálás. 

A visszakérdezés többször is megtörténhet, egészen addig amíg nem történik három egymást követõ fordítási hiba (ekkor feltételezzük, hogy a modell nem fogja tudni megoldani a szintaktikailag helyes tesztgenerálást), 
vagy öt olyan generálás, ahol nem történt fordítási hiba, de nem az elvárt eredményt kaptuk. Azaz a sérülékeny állapot átment a generált teszten, vagy a javított változat bukott meg.

Fontos megjegyezni, hogy a kiértékelés alatt minden példához kapcsolódó generálás esetében a legjobb generációt vettük figyelembe. Ez csupán annyit jelent, hogy ha egyszer is történt nem fordítási hibás generálás, 
akkor a kiértékelõ azt a naplófájlt külön megtartotta és a végsõ eredményekbe ez az eset került bejegyzésre. 

\subsubsection{Futási eredmények}
Tehát a bejegyzett eredmények példánként két részre oszlanak. Ahogy korábban említettük, a futtatás és tesztelés elõször a sérülékeny változattal történik meg (before patch), majd utána a javítottal (after patch).
Mind a két esethez három lehetséges érték társul.

\begin{itemize}
  \item \textbf{ERROR}: A generált teszt fordítási hibát tartalmaz
  \item \textbf{SUCCESS}: A generált teszt az adott állapotban sikeresen lefutott és átment
  \item \textbf{FAILURE}: A generált teszt az adott állapotban rossz várt értékkel tért vissza
\end{itemize}

A ~\ref{chap:results}. fejezetben tárgyalni fogunk néhány olyan esetrõl, ahol felmerült olyan helyzet, ahol ezek a visszajelzések önmagukban nem tartalmazzák a teljes tényszerû eredményt, 
emiatt is volt fontos a következõ szekcióban tárgyalt emberi evaluálás. 

\section{Manuális kiértékelés}
\label{sec:methodology-maneval}

A teljesen automatikus és szigorú validálás mellett gondoskodtunk a szubjektív, emberi kiértékelésérõl is a generált teszteknek.
Az egységtesztek elkészítéséhez egy fejlesztõnek is rengeteg releváns háttérinformációval kell rendelkezzen már ahhoz is, hogy egyáltalán olyan tesztet készítsen egy adott programhoz, ami futtatható.
Ezért döntöttünk úgy, hogy a tesztek hasznosságának felmérése érdekében megtekintjük az egyes tesztek felépítését és kézzel is elbíráljuk hasznosságát, szemantikai (és akár) általános szintaktikai helyességét.

Két esetre bontottuk a kézi kiértékelés véleményezését:
\begin{itemize}
  \item Szemantikailag rossz
  \item Szemantikailag jó
\end{itemize}

Természetesen a szigorú validáláskor helyes kimenetet produkáló eseteket is ellenõriztük kézzel.

%kiértékelõ környezet:

%-lefuttattuk az extrém menõ evaluáló eszközt, ami 5 lépésbõl validált egy generált tesztet:

%1. megépítette a megfelelõ kontextust

%2. átadta a promptot a kontextussal a gptnek

%3. a visszakapott válaszból kiszedte a java kódot

%4. bevágta dockerbe és lefuttatta a tesztet amit generált a gpt a sebezhetõ metódussal és a javítottal is

%5. a logok alapján értelmezte, hogy sikeresen lefutott e a teszt 

%-kellett egy nagyon jó prompt, ezt kitaláltuk ügyesen

%-a kigyûjtött kontextus darabokból létrehoz egy java fájlt ami tartalmazza a megfelelõ kontextus szintû adatokat

%-gpt4 turbóval végeztük a vizsgálatot, õ képezi a következõ lépést, átadja a promptot és a kontextust neki

%-elmenti a válaszát

%-megfogja a választ és szépen kiszedi belõle a java kódot, amennyiben van és a megfelelõ névvel bemásolja az adatgyûjtés alatt elmentett teszt mappába, ahol kizárólag csak azt a tesztet futtatjuk

%-vul4j dockerbõl lefuttatja a projekt tesztjét és evaluálja a logokat

%-ezek az eredmények nem kõbevésett tények, mert a build környezet minden projektnél más specifikációkkal mûködik, ezért néhány helyen szükséges a kézi felülbírálás

%kézi kiértékelés:

%-a megszületett eredményeket átnézzük

%-a technikai háttérinformációk hiányában elõfordulhat, hogy a generált teszt nem fut, viszont szemantikailag jó

% ide volt a fos1

%fos2

\chapter{Eredmények}
\label{chap:results}

A ~\ref{sec:methodology-evalenv}. szakaszban említettük, hogy minden példára, akár több mint négyszer, történt generálás a modell által és mindig az utolsó legjobb eredményt vettük figyelembe. 
A kiértékelés részletes eredményeit a ~\ref{tab:sum}. táblázat ábrázolja. Szintén említésre került, hogy az eredmények automatikus és manuális, kézi validáláson is átestek. 
Tehát a 20 példa minden kontextus szintével történt futtatás, ami azt jelenti, hogy 80 darab eredménypár született az automata kiértékelés során, ez magába foglal változó mennyiségû visszakérdezéses generálást is.


\section{Szintaktikai elemzés}

A szintaktikai elemzés során arra voltunk kíváncsiak, hogy mindenféle emberi beavatkozás nélkül képes-e a GPT olyan egységteszt generálásra, amely univerzálisan megállja a helyét egy tesztkörnyezetben,
annak függvényében, hogy a modell megkapta utasításként, az egyszerû Java nyelvi elemeket használjon a válasz során. Elõfordultak olyan esetek, ahol a futtató környezet extra jelölést igényelt a teszt lefuttatása 
érdekében. Ezen kontextus hiánya miatt voltak olyan generálások, ahol maga a teszt az automatikus evaluálás során nem futott le, de a projekt fordítási folyamatába beletartozott.
Az utóbb említett tényezõ alapján az ilyen eseteket is elfogadtuk szintaktikailag helyes eredménynek. 

Azokat az eseteket, ahol a sérülékeny és javított változat egyaránt 
- hány százalékban volt forduló kód? kérdés megválaszolása

\section{Szemantikai elemzés}

- hány százalékban volt sikeres szintaktikai és szemantikai generálás? kérdés megválaszolása

\section{Kontextus hatása a pontosságra}

- hogyan befolyásolja a context a pontosságot? kérdés megválaszolása

\section{A generálás szubjektív hasznossága}

- a generált tesztek (szubjektívan) használhatók? kérdés megválaszolása

\section{Egyéb tapasztalatok}

- milyen hatással volt a prompt

- hogyan segített a visszakérdezés

\chapter{Limitációk}

-csak egy modellt néztünk, GPT4

-nincs elõtanítás / finetuning

-kicsi adathalmaz

-szubjektív használhatóság

-semmi extra adatot nem tartalmazott a prompt, csak a feladatot és a kódot


\chapter{Konklúzió}

-nem haszontalan ez a cucc, a limitációkban leírt bõvítésekkel csak jobb lehet.

\ldots

%% Az itrodalomjegyzek keszitheto a BibTeX segedprogrammal:
%\bibliography{diploma}
%\bibliographystyle{plain}

%VAGY "kézzel" a következõ módon:

%\begin{thebibliography}{9}
%10-nél kevesebb hivatkozás esetén

\begin{thebibliography}{99}
% 10-nél több hivatkozás esetén

\addcontentsline{toc}{section}{Irodalomjegyzék}
\bibliographystyle{unsrt}
\bibliography{references}

%Elso szerzok vezetekneve alapjan ábécérendben rendezve.


%folyóirat cikk: szerzok(k), a folyóirat neve kiemelve,
%az evfolyam felkoveren, zarojelben az evszam, vegul az oldalszamok es pont.

\bibitem{cve}
Common Vulnerabilities and Exposures.
\url{https://cve.mitre.org/}, 2023%, 199--224.


\bibitem{cwe}
Common Weakness Enumeration.
\url{https://cwe.mitre.org/}, 2023%, 199--224.


\bibitem{vul4j}
Quang-Cuong Bui, Riccardo Scandariato, and Nicolás E. Díaz Ferreyra.
\emph{Vul4j: A dataset of reproducible Java vulnerabilities geared towards the study of program repair techniques}, 2023%, 199--224.

\bibitem{focal_context}
Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, Neel Sundaresan.
\emph{Unit Test Case Generation with Transformers and Focal Context}, 2021%, 199--224.

\bibitem{01}
Quanjun Zhang, Chunrong Fang, Bowen Yu, Weisong Sun, Tongke Zhang, Zhenyu Chen.
\emph{Pre-trained Model-based Automated Software Vulnerability Repair: How Far are We?}, 2023%, 199--224.

\bibitem{02}
Michael Fu, Chakkrit (Kla) Tantithamthavorn, Van Nguyen, Trung Le.
\emph{ChatGPT for Vulnerability Detection, Classification, and Repair: How Far Are We?}, 2023%, 199--224.

\bibitem{03}
Benjamin Steenhoek, Michelle Tufano, Neel Sundaresan, Alexey Svyatkovskiy.
\emph{Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation}, 2023%, 199--224.


\bibitem{05}
Kamel Alrashedy, Abdullah Aljasser.
\emph{Can LLMs Patch Security Issues?}, 2024%, 199--224.

\bibitem{06}
Mohammed Latif Siddiq, Joanna C. S. Santos, Ridwanul Hasan Tanvir, Noshin Ulfat, Fahmid Al Rifat, Vinícius Carvalho Lopes.
\emph{An Empirical Study of Using Large Language Models for Unit Test Generation}, 2024%, 199--224.

\bibitem{07}
Nadia Alshahwan, Jubin Chheda, Anastasia Finegenova, Beliz Gokkaya, Mark Harman, Inna Harper, Alexandru Marginean, Shubho Sengupta, Eddy Wang.
\emph{Automated Unit Test Improvement using Large Language Models at Meta}, 2024%, 199--224.

\bibitem{08}
Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang.
\emph{Software Testing with Large Language Models: Survey, Landscape, and Vision}, 2024%, 199--224.

\bibitem{085}
Sungmin Kang, Juyeon Yoon, Shin Yoo.
\emph{Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction}, 2023%, 199--224.

\bibitem{09}
Kunal Taneja, Tao Xie.
\emph{DiffGen: Automated Regression Unit-Test Generation}, 2008%, 199--224.

\bibitem{10}
Alok Mathur, Shreyaan Pradhan, Prasoon Soni, Dhruvil Patel, Rajeshkannan Regunathan.
\emph{Automated Test Case Generation Using T5 and GPT-3}, 2023%, 199--224.

\bibitem{11}
Chunqiu Steven Xia, Yuxiang Wei, Lingming Zhang.
\emph{Automated Program Repair in the Era of Large Pre-trained Language Models}, 2023%, 199--224.

\bibitem{12}
Xing Hu, zirui Chen, Xin Xia, Yi Gao, Tongtong Xu, David Lo, Xiaohu Yang
\emph{Exploiting Library Vulnerability via Migration Based Automating Test Generation}, 2023%, 199--224.

\bibitem{erzelmi_stimulacio}
Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie.
\emph{Large language models understand and can be enhanced by emotional stimuli}, 2023%, 199--224.


%könyv (szerzo(k), a könyv neve kiemelve, utana a kiado, a kiado szekhelye, az evszam es pont.)
%\bibitem{Pin}
%J.-E. Pin,
%\emph{Varieties of Formal Languages},
%Plenum Publishing Corp., New York, 1986.





\end{thebibliography}




\end{document}

%fos1
%\chapter{Egyebek}

%\section{Környezetek}
%\begin{tét}
%\label{tét-alap}
%Ez itt egy tétel.
%\end{tét}

%A bizonyítás \begin{proof} és \end{proof} közé kerül:
%\begin{proof}
%Ez pedig a bizonyítása, melyben szerepel egy képlet:
%\begin{equation}
%\begin{split}
%E^{\text{globális}} &= \text{tét}_1\cdot E_1^{\text{elemi}}+\text{tét}_2\cdot
%E_2^{\text{elemi}}+\ldots+\text{tét}_n\cdot E_n^{elemi} \\
%&=E^{\text{elemi}}\left(\text{tét}_1+\text{tét}_2+\ldots+\text{tét}_n\right)\\
%&=E^{\text{elemi}}\cdot\text{össztét}
%\end{split}
%\end{equation}
%A második egyenlõségnél azt használtunk ki, hogy ...

%Ezzel a bizonyítást befejeztük.
%\end{proof}

%\begin{defi}
%\label{def-pelda}
%Ez egy definíció. Számozása a tételekkel együtt történik.
%\end{defi}

%\begin{áll}
%A követekezõ négy állítás egymással ekvivalens:
%\label{áll-ekvivalencia}
%  \begin{itemize}
%  \item[(i)] $M$ és $N$ gyengén ekvivalensek.
%  \item[(ii)] Minden $n$
%  nemnegatív egész számra $|L_{M}\cap \Sigma_{1}^{n}|=|L_{N}\cap \Sigma_{2}^{n}|$ teljesül.
%  \item[(iii)] Minden $n$ nemnegatív egész szám esetén
%   létezik
%  $ \pi_{n}: L_{M}\cap \Sigma_{1}^{n} \rightarrow L_{N}\cap \Sigma_{2}^{n} $ kölcsönösen egyértelmû
%  leképezés.
%  \item[(iv)] Minden nemnegatív $n$-re $x A^{n} y^{T}=x' A'^{n} y'^{T}$.
%  \end{itemize}
%\end{áll}

%\begin{köv}
%  Ez pedig egy következmény.
%\end{köv}

%\begin{pld}
%  Ez lesz a példa, ezt nem szedjük dõlten.
%\end{pld}

%\begin{megj}
%  A fejezetet pedig egy megjegyzés zárja.
%\end{megj}


%\section{valami}

%Ez egy fa:
%\begin{itemize}
%    \item elsõ
%    \item második
%      \subitem elsõ
%      \subitem második
%    \item harmadik
%    \item[$\clubsuit$]  saját jel is alkalmazható
%\end{itemize}
%Ez pedig egy számozott lista:
%\begin{enumerate}
%            \item hétfõ
%            \item kedd
%            \item szerda
%\end{enumerate}

%Oldaltörést is alkalmazhatunk
%\pagebreak

%\section{Egy táblázat és egy ábra}
\iffalse
A táblázat itt következik.
\begin{table}[!h]\label{strategia}
\caption{Példa stratégiatáblára a Black Jack esetében}
\begin{center}
\begin{tabular}{l||r|r|r|r|r|r|r|r|r|r}
&ász&2&3&4&5&6&7&8&9&10\\
\hline\hline
21&n&n&n&n&n&n&n&n&n&n\\
20&n&n&n&n&n&n&n&n&n&n\\
19&n&n&n&n&n&n&n&n&n&n\\
18&n&n&n&n&n&n&n&n&n&n\\
17&n&n&n&n&n&n&n&n&n&n\\
16&h&n&n&n&n&n&h&h&b&b\\
15&h&n&n&n&n&n&h&h&h&b\\
14&h&n&n&n&n&n&h&h&h&b\\
13&h&n&n&n&n&n&h&h&h&h\\
12&h&n&n&n&n&n&h&h&h&h\\
11&h&D&D&D&D&D&D&D&D&h\\
\end{tabular}
\end{center}
\end{table}

Lássunk egy ábrát is!
\begin{figure}[!h]
\unitlength 8mm
\begin{center}
\begin{picture}(8,6)
\thicklines
\multiput(0,1)(0,1){2}{\line(1,0){5}}
\multiput(3,0)(1,0){2}{\line(0,1){6}}
\multiput(1,0)(1,0){2}{\line(0,1){1}}
\multiput(6,0)(1,0){2}{\line(0,1){5}}
\multiput(0,1)(1,0){3}{\line(0,1){1}}
\multiput(2,4)(3,0){3}{\line(0,1){1}}
\multiput(3,0)(0,3){3}{\line(1,0){1}}
\multiput(6,0)(0,1){4}{\line(1,0){1}}
\multiput(7,2)(0,1){2}{\line(1,0){1}}
\multiput(2,4)(0,1){2}{\line(1,0){6}}
\put(5,1){\line(0,1){1}}
\put(8,2){\line(0,1){1}}
\put(1,0){\line(1,0){1}}
\put(1,1){\makebox(1,1){\(\sphericalangle\)}}
\put(7,2){\makebox(1,1){\(\$\)}}
\end{picture}
\end{center}
\caption{\label{labirintus}Labirintus bejárása}
\end{figure}

%laptörés:
\newpage

Külön fájlban elkészített grafika beillesztését a \ref{abra-automata} ábra szemlélteti.
\begin{figure}[h]
\centering
%A psfrag csomag használatával a (encapsulated)postcript abra feliratait LaTeX koddal helyettesíthatjük:
\psfrag{a}[c][c]{$q_0$}
\psfrag{b}[c][c]{$q_1$}
\psfrag{c}[c][c]{$q_2$}
\psfrag{d}[c][c]{$q_3$}
\psfrag{e}[c][c]{$q_4$}
\psfrag{f}[c][c]{$q_5$}
\psfrag{g}[c][c]{$q_6$}
\psfrag{h}[c][c]{$q_7$}
\psfrag{0}[c][c]{$a_{0}$}
\psfrag{9}[c][c]{$a_{9}$}
\psfrag{3}[c][c]{$a_{3}$}
\psfrag{12}[c][c]{$a_{12}$}
\psfrag{15}[c][c]{$a_{15}$}
%Garfika belillesztese, "scale2 a nagyitas/kicinyites merteke, itt 80%.
\includegraphics[scale=0.8]{abra.eps}
\caption{\label{abra-automata} A $4\times m$-es tábla lefedéseinek mátrixreprezentációit felismerõ automata}
\end{figure}
\fi


%fos2
\iffalse
A függelékbe kerülhetnek a hosszú táblázatok, vagy mondjuk egy programlista:
% A verbatim kornyezet hasznalatanal ügyeljünk rá, hogy az editor a szóközöjket át ne írja tab karakterekre!
\begin{verbatim}
   while (ujkmodosito[i]<0)
   {
      if (ujkmodosito[i]+kegyenletes[i]<0)
      {
         j=i+1;
         while (j<14)
         if (kegyenletes[i]+ujkmodosito[j]>-1) break;
         else j++;
         temp=ujkmodosito[j];
         for (l=i;l<j;l++) ujkmodosito[l+1]=ujkmodosito[l];
         ujkmodosito[i]=temp;
      }
      i++;
   }
\end{verbatim}
\fi

%\chapter*{Nyilatkozat}

%Egy üres sort adunk a tartalomjegyzékhez:
%\addtocontents{toc}{\ }
%\addcontentsline{toc}{section}{Nyilatkozat}
%\hspace{\parindent}

% A nyilatkozat szövege más titkos és nem titkos dolgozatok esetében.
% Csak az egyik tipusú myilatokzatnak kell a dolgozatban szerepelni
% A ponok helyére az adatok értelemszerûen behelyettesídendõk es
% a szakdolgozat /diplomamunka szo megfeleloen kivalasztando.


%A nyilatkozat szövege TITKOSNAK NEM MINÕSÍTETT dolgozatban a következõ:
%A pontokkal jelölt szövegrészek értelemszerûen a szövegszerkesztõben és
%nem kézzel helyettesítendõk:

%\noindent
%Alulírott \makebox[4cm]{\dotfill} szakos hallgató, kijelentem, hogy a dolgozatomat a Szegedi Tudományegyetem, Informatikai Intézet \makebox[4cm]{\dotfill} Tanszékén készítettem, \makebox[4cm]{\dotfill} diploma megszerzése érdekében.

%Kijelentem, hogy a dolgozatot más szakon korábban nem védtem meg, saját munkám eredménye, és csak a hivatkozott forrásokat (szakirodalom, eszközök, stb.) használtam fel.

%Tudomásul veszem, hogy szakdolgozatomat / diplomamunkámat a Szegedi Tudományegyetem Diplomamunka Repozitóriumában tárolja.

%\vspace*{2cm}

%\begin{tabular}{lc}
%Szeged, \today\
%\hspace{2cm} & \makebox[6cm]{\dotfill} \\
%& aláírás \\
%\end{tabular}


%\vspace*{4cm}