% LaTeX mintafájl szakdolgozat és diplomamunkáknak az
% SZTE Informatikai Tanszekcsoportja által megkövetelt
% formai követelményeinek megvalósításához
% Modositva: 2011.04.28 Nemeth L. Zoltan
% A fájl használatához szükséges a magyar.ldf 2005/05/12 v1.5-ös vagy késõbbi verziója
% ez letölthetõ a http://www.math.bme.hu/latex/ weblapról, a magyar nyelvû szedéshez
% Hasznos információk, linekek, LaTeX leirasok a www.latex.lap.hu weboldalon vannak.
%


\documentclass[12pt]{report}

\usepackage{url}
\usepackage{listings}
\lstset{captionpos=b}

\usepackage{setspace}

\usepackage[bottom]{footmisc}

%Magyar nyelvi támogatás (Babel 3.7 vagy késõbbi kell!)
\def\magyarOptions{defaults=hu-min}
\usepackage[magyar]{babel}

%Az ékezetes betûk használatához:
\usepackage{t1enc}% ékezetes szavak automatikus elválasztásához
\usepackage[latin2]{inputenc}% ékezetes szavak beviteléhez

% A formai kovetelmenyekben megkövetelt Times betûtípus hasznalata:
\usepackage{times}


\usepackage{setspace} % For controlling line spacing

%Az AMS csomagjai
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

%A fejléc láblécek kialakításához:
\usepackage{fancyhdr}

\usepackage{fancybox,framed}

% definecolor
%\usepackage{xcolor}

%Please add the following packages if necessary:
\usepackage{booktabs, multirow} % for borders and merged ranges
\usepackage{soul}% for underlines
\usepackage[table]{xcolor} % for cell colors
\usepackage{changepage,threeparttable} % for wide tables

%Természetesen további csomagok is használhatók,
%például ábrák beillesztéséhez a graphix és a psfrag,
%ha nincs rájuk szükség természetesen kihagyhatók.
\usepackage{graphicx}
\usepackage{psfrag}

%Tételszerû környezetek definiálhatók, ezek most fejezetenkent egyutt szamozodnak, pl.
\newtheorem{tét}{Tétel}[chapter]
\newtheorem{defi}[tét]{Definíció}
\newtheorem{lemma}[tét]{Lemma}
\newtheorem{áll}[tét]{Állítás}
\newtheorem{köv}[tét]{Következmény}

%Ha a megjegyzések és a példak szövegét nem akarjuk dõlten szedni, akkor
%az alábbi parancs után kell õket definiální:
\theoremstyle{definition}
\newtheorem{megj}[tét]{Megjegyzés}
\newtheorem{pld}[tét]{Példa}

%Margók:
\hoffset -1in
\voffset -1.5in
\oddsidemargin 35mm
\textwidth 150mm
\topmargin 15mm
\headheight 10mm
\headsep 5mm
\textheight 237mm

% bolondba
\linespread{1.5}
%\setstretch{1.5}
\sloppy

% Kódrészletes színezése
\input{listings_def}
\renewcommand{\lstlistingname}{Kódrészlet}


\begin{document}

%A FEJEZETEK KEZDÕOLDALAINAK FEJ ES LÁBLÉCE:
%a plain oldalstílust kell átdefiniálni, hogy ott ne legyen fejléc:
\fancypagestyle{plain}{%
%ez mindent töröl:
\fancyhf{}
% a láblécbe jobboldalra kerüljön az oldalszám:
\fancyfoot[R]{\thepage}
%elválasztó vonal sem kell:
\renewcommand{\headrulewidth}{0pt}
}

%A TÖBBI OLDAL FEJ ÉS LÁBLÉCE:
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Sérülékenységet tanúsító egységtesztek automatikus generálásának vizsgálata}
\fancyfoot[R]{\thepage}


%A címoldalra se fej- se lábléc nem kell:
\thispagestyle{empty}

\begin{center}
\begin{singlespace}
%\vspace*{1cm}
{\Large\bf Szegedi Tudományegyetem}

\vspace{0.5cm}

{\Large\bf Informatikai Intézet}

\vspace*{3cm}


{\LARGE\bf Sérülékenységet tanúsító egységtesztek}\\
\vspace{2mm}
{\LARGE\bf automatikus generálásának vizsgálata}


\vspace*{2.6cm}

{\Large TDK dolgozat}
% vagy {\Large Szakdolgozat}

\vspace*{2cm}

%Értelemszerûen megváltoztatandó:
%{\large
%\begin{tabular}{c@{\hspace{2cm}}c}
%\emph{Készítette:} &\emph{Témavezetõk:}\\
%\bf{Isztin Martin} &\begin{tabular}{@{\hspace{0.5cm}}c@{\hspace{1.5cm}}c}\bf{Dr. Antal Gábor} &\bf{Dr. Bán Dénes}\\\end{tabular}\\
%programtervezõ informatikus &\begin{tabular}{@{\hspace{3cm}}c@{\hspace{1.5cm}}c@{\hspace{1cm}}}adjunktus  &tudományos munkatárs\\\end{tabular}\\	
%\end{tabular}
%}

{\large
\noindent
\emph{Készítette:}\\
{\bf Isztin Martin}\\
{\textit {programtervezõ informatikus}}\\
\vspace{0.1cm}
{\textit {III. évf. BSc hallgató}}
}

\vspace*{1.5cm}

{\large
\noindent
\emph{Témavezetõk:}\\
{\bf Dr. Antal Gábor}\\
{\textit {adjunktus}}\\
}

\vspace*{0.3cm}

{\large
\noindent
{\bf Dr. Bán Dénes}\\
{\textit {tudományos munkatárs}}\\
}

\vspace*{2.3cm}

{\Large
Szeged
\\
\vspace{2mm}
2024
}
\end{singlespace}
\end{center}


%A tartalomjegyzék:
\tableofcontents

%A \chapter* parancs nem ad a fejezetnek sorszámot
\chapter*{Absztrakt}
%A tartalomjegyzékben mégis szerepeltetni kell, mint szakasz(section) szerepeljen:
\addcontentsline{toc}{section}{Absztrakt}

\begin{spacing}{1.4}
Egy szoftver fejlesztésének életciklusában fontos minõségbiztosítási szerepet játszik a tesztelés. 
Megfelelõ tesztekkel a kód lefedettségének növelésén és a regressziók elkerülésén felül arról is megbizonyosodhatunk, 
hogy egy esetleges sérülékenység jelen van-e a szoftverünkben - és hogy azt egy potenciális javítás valóban javítja-e. 
Ám az ilyen tesztek elkészítése bonyolult, költséges és manuális folyamat.

Hogy segítsük mind a tesztelõk, mind a biztonsági szakértõk munkáját, ebben a dolgozatban az egyik legelterjedtebb nyelvi modell, 
a ChatGPT automatikus egységteszt generálási képességét kutatjuk a sérülékenységek szemszögébõl. 
A VUL4J nevezetû, tanúsított CWE sebezhetõségekkel és hozzájuk tartozó javításokkal rendelkezõ Java projektgyûjtemény egy részhalmazán vizsgáljuk, 
hogy a GPT képes-e a javítás elõtti és utáni kódállapot együttes ismeretében szintaktikailag és/vagy szemantikailag  helyes egységteszteket generálni az adott sérülékenység kivédésének bizonyítékaként. 
Figyelmet fordítunk ezen belül a kódkontextus bõségének hatására, a GPT ön-hibajavítási képességének hatékonyságára és a generált tesztesetek szubjektív hasznosíthatóságára.

Eredményeink azt mutatják, hogy a GPT domain-specifikus elõtanítás nélkül is szintaktikailag korrekt teszteseteket generál az esetek 50\%-ában. 
És habár a javítások szemantikai helyessége csak az esetek 15\%-ban volt automatikusan validálható, szubjektív kiértékelésünk alapján a GPT az esetek többségében olyan teszt sablont generál, 
ami minimális emberi finomhangolással teljes értékû sérülékenység igazolássá fejleszthetõ tovább. 
Tehát a kis mennyiségû rendelkezésre álló adat ellenére már ezek a korai eredmények is arra engednek következtetni, 
hogy a GPT sikerrel használható a sérülékenység-tesztelésben - ha nem is teljesen autonóm módon, de egy intelligens támogatói folyamat részeként mindenképp.	

%\vspace{12pt}
{\bf Kulcsszavak:} generált egységtesztek, nyelvi modell, sérülékenység, CWE, kontextus szintek
\end{spacing}



%\chapter*{Tartalmi összefoglaló}
%\addcontentsline{toc}{section}{Tartalmi összefoglaló}

%A tartalmi összefoglalónak tartalmaznia kell (rövid, legfeljebb egy oldalas, összefüggõ megfogalmazásban)
%a következõket: a téma megnevezése, a megadott feladat megfogalmazása - a feladatkiíráshoz viszonyítva-,
%a megoldási mód, az alkalmazott eszközök, módszerek, az elért eredmények, kulcsszavak (4-6 darab).

%Az összefoglaló nyelvének meg kell egyeznie a dolgozat nyelvével. Ha a dolgozat idegen nyelven készül,
%magyar nyelvû tartalmi összefoglaló készítése is kötelezõ (külön lapon), melynek terjedelmét a TVSZ szabályozza.

%\chapter*{Bevezetés}
\chapter{Bevezetés}
%\addcontentsline{toc}{section}{Bevezetés}

A mai napig rengeteg olyan szoftver lát napvilágot a fogyasztói világban, amelyben sérülékenységek találhatók. Ezek mindaddig észrevétlenek maradnak, amíg valaki ki nem használja õket.
Sajnos nem elég csupán szemmel ellenõrizni egy programkód hitelességét egy tapasztalt személynek sem, mivel akár olyan kódrészlet is okozhat sebezhetõséget, amely egy másik környezetben teljesen ártalmatlan.
Az ilyen hibák kijavítása rengeteg idõ és pénzügyi áldozattal jár. Egy szoftverben rejlõ sebezhetõségek szerencsére hamar észrevehetõk és kiküszöbölhetõk megfelelõ mértékû teszteléssel, azonban ezeknek a megírása 
szintén erõforrásigényes feladat.


Léteznek olyan adatbázisok, amelyek gyakori nyilvánosságra hozott sérülékenységeket dokumentálnak. 
A CVE (\textit{Common Vulnerabilities and Exposures})~\cite{cve} valós rendszerek kiberbiztonsági sérülékenységeirõl tartalmaz információkat. Az itt található bejegyzésekhez
társul egy azonosító is, amely egy adott sérülékenységet reprezentál. Ezen sérülékenységek általánosabb kategorizálása a CWE (\textit{Common Weakness Enumeration})~\cite{cwe} azonosítókkal történik.

A mára már szinte bárkinek elérhetõ nagy nyelvi modellek széleskörûen elterjedtek produktivitásnövelõ technológiaként és a modellek által nyújtott lehetõségek miatt 
a szoftverfejlesztés számos területén szintén használják.
Számos kutatás számol be a feltörekvõ technológia automatikus programjavító képességeirõl, viszont az ezt próbáratevõ egységtesztek generálásáról kevés információt tudunk.

% ide mondjuk vul4j átvezetés
A dolgozat célja a gyakorlatban felismert sebezhetõségekhez való egységteszt generálás, ezért a kiértékelés során a VUL4J~\cite{vul4j} projektgyûjtemény részhalmazát használtuk, amely számos Java nyelven íródott valós rendszer sérülékenységeirõl
tartalmaz információkat, többek között a sérülékenység javítását, a sérülékenységhez tartozó CVE és többnyire CWE azonosítót.
További elõnyei az adathalmaznak, hogy a biztosított környezettel könnyedén lehet alternálni a a projekt sérülékeny és javított változatai között, 
elérhetõk a sérülékenység javításával alkalmazott változtatások és a projektben eredetileg használt egységtesztek is. 

A kiértékeléshez használt részhalmazunk 20 olyan példát tartalmaz, amelyet igyekeztünk úgy kiválasztani, hogy minél több sérülékenység fajtát lefedjen.
Minden példát fokális kontextusokra bontottunk~\cite{focal_context}, amely négy szintbõl állt (0-3).
A kutatás során az egyik legismertebbek nyelvi modellt használtuk, az OpenAI cég generatív elõtanított traszformer modellje, a GPT-t, ezen belül is a legfrissebb GPT-4 Turbo változatát.
A bemenetként adott szöveghez (promptoláshoz) kizárólag egy szerepet (szerepjáték keretein belül, itt most a modell egy senior szoftvertesztelõ) és a rendelkezésre álló kódot adtuk át. 
Az eredmények osztályozása két részre különíthetõ. Elõször egy automatizált környezetben végeztük el a kontextus legyártását, promptolást, a kapott válasz feldolgozását és a kiértékelését, aztán kézzel is 
felülbíráltuk a generálások szubjektív használhatóságát.

A kutatás a következõ kérdésekre keresi a választ:

\begin{itemize}
\item RQ1: Hány százalékban kaptunk szintaktikailag helyes kódot?
\item RQ2: Hány százalékban kaptunk szemantikailag is helyes kódot?
\item RQ3: Hogyan befolyásolja a kontextus a generálás pontosságát?
\item RQ4: Milyen a szubjektív használhatósága a generált teszteknek?
\end{itemize}

Eredményeink azt mutatják, hogy a GPT domain-specifikus elõtanítás nélkül is szintaktikailag korrekt teszteseteket generál az esetek 50\%-ában, amely bíztató eredmény annak tudatában, hogy semmilyen
technikai háttérinformációt nem adtunk át a promptolás során. A tesztesetek szemantikai helyessége 15\%-ban volt automatikusan validálható, ennek ellenére a szubjektív, kézi kiértékelésünk során a GPT az esetek
többségében ez sokkal nagyobb arányban generált hasznos sablont a fejlesztõk számára.
Ez mutatja, hogy a nagy nyelvi modellek kellõ finomhangolással nagyon hasznos részét képezhetik ezen fontos munkafolyamatnak is.

A dolgozat felépítése a következõképpen alakul: a 2. fejezetben a témához kapcsolódó munkákat tárgyaljuk meg, majd a 3. fejezetben ismertetjük a kutatás módszertanát. 
A 4. fejezetben részletesen bemutatjuk a kutatás eredményeit, majd a speciális esetekrõl ejtünk szót.
A 5. fejezetben a limitációkról és a jövõbeli lehetõségekrõl számolunk be, végül a 6. fejezet zárja le a dolgozatot.


%-minden adat megvan ahhoz, hogy megnézzük jól tud e generálni unittestet a GPT (sebezhetõ metódus, patchelt metódus, különbözõ kontextus szintek, akár CWE is)

%-eredmények roughly

%-tdk felépítése, mire keresünk választ

%  RQ1: Hány százalékban kaptunk szintaktikailag helyes kódot?

%  RQ2: Hány százalékban kaptunk szemantikailag is helyes kódot?

%  RQ3: hogyan befolyásolja a context a pontosságot?

%  RQ4: szubjektív használhatósága a generált teszteknek



\chapter{Kapcsolódó munkák}

\section{Nagy nyelvi modellek a sérülékenység analízisben}

A nagy nyelvi modellek széleskörûen használtak a sérülékenység analízisben. A legjelentõsebb iránya az APR (Automated Program Repair), amirõl számos tanulmány szól.
Quanjun Zhang és társai összevetették a VRepair transzfer-tanuló neurális hálózati modell APR képességeit számos nagy nyelvi modellel~\cite{01}, köztük a CodeBERT-tel, UniXcoderrel és CodeGPT-vel.
Fõ eredményként fény derült a tényre, hogy a nagy nyelvi modellek 10.21\% és 22.23\% közti értékkel pontosabban hajtották végre a javításokat.

Egy másik tanulmány keretein belül Michael Fu és társai kifejezetten a ChatGPT-t használták a modell APR képességeinek felmérésére~\cite{02} a Big-Vul nevezetû adathalmazon, amely C++ nyelvben íródott  
projektek függvényeinek sérülékeny és javított változatait egyaránt tartalmazza, CVE, CWE azonosítókkal együtt, további egyéb technikai információkkal. A ChatGPT finomhangolások nélkül hátramarad a kódspecifikus
modellekkel szemben.

A GPT adottságain túl Kamel Alrashedy és társa a CodeLlama nevezetû modellt is megvizsgálta~\cite{05} egy Python sebezhetõségi adatbázissal, visszajelzés vezérelt hibajavítással, miszerint a modell egy másik példánya 
véleményezi az eredeti példány válaszát, majd ezen vélemény alapján történik az eredeti példány válaszának finomhangolása. Ezzel a megközelítéssel 5-10\%-kal jobb eredményeket értek el.

A témánkhoz releváns ötletként megemlíthetõ Chunqiu Steven Xia csapatának ötlete~\cite{11}, amelyben a generált hibajavítás helyességét megadott tesztekkel validálják.

A nagy nyelvi modellek ilyen módú alkalmazhatóságának fényében mi a sérülékenységek témakörét vesszük célba, és mi is a ChatGPT segítségével, 
de mi javítások automatizálása helyett már létezõ javítások helyességét szeretnénk ellenõrizni a hozzájuk tartozó tesztesetek generálása által.

\section{Nagy nyelvi modellek a teszteset generálásban}

Egy tanulmány statikus metrikákat alkalmazva finomhangolta a modelleket, a magas minõségû egységtesztek generálására~\cite{03}, miszerint egy alap modell 17\%-ban szintaktikailag hibás, 
31\%-ban állítás (assertion) nélküli tesztet generál és az esetek 37\%-ában nem hívja meg a tesztelendõ metódust. Az erõsítéses tanítás eredményeként felügyelt finomhangolással és az RLSQM 
(Reinforcement Learning from Static Quality Metrics) alkalmazása után ezek a számok lecsökkentek 1\%, 5\% és 10\% környéki értékekre. A finomhangolás során, hozzánk hasonlóan dinamikus kontextushosszt használtak, 
ami akár az egész fájl szövege volt, egy egész osztály, csak a metódus fejlécek, vagy csak a metódus maga.

Michele Tufano és csapata szintén különbözõ fokális kontextusszintekkel kísérleteztek az egységteszt generálás~\cite{focal_context} promptolása során. Ez a megközelítés sokkal hasonlóbb ahhoz az átadott dinamikus kontextushoz, 
amit mi választottunk. Kezdve kizárólag a fokális metódustól, hozzáadva szintenként az osztály nevét, a konstruktor fejléceit, a metódusok fejléceit és végül az osztály mezõit.
A használt modell tanítása progresszíven történt. Történt egy angol nyelvû elõtanítés, utána egy kódbázisú, végül egy teszteset generáláshoz kapcsolódó finomhangolás.
A generálás egy fordítási folyamatnak van értelmezve, fokális kontextusról tesztesetre.

Egy empirikus tanulmányban szintén új kutatási dimenziót képezett a kontextus hatása a teszt generálására vonatkozóan, habár itt a kontextus máshogy játszik szerepet. A különbözõ szinteket a Java dokumentáció 
jelenléte és specifikussága definiálta~\cite{06}. Három szintje a következõképp épült fel: Javadoc nélküli kontextus, részleges Javadoc (használati példák nélkül) és teljes Javadoc implementáció nélkül.
Az osztály, a javítást megelõzõ és a javított metódus mindig szerepel a bemenetben.
A generált tesztek 40-70\%-a nem okoz fordítási hibát, szubjektív kiértékelés során ez az arány sokkal nagyobb, 75-100\%. 50-80\%-ban helyes generálás történt és 70-90\% volt a kódlefedettség.
Egyéb érdekesség, hogy elõzetes munkálatok kimutatják, hogy a nagy nyelvi modellek jobban teljesítenek gyengén típusos nyelvek használata során.

Egy Meta cég által kiállított tanulmányban~\cite{07} nem generálnak konkrét "nyers" teszteket, hanem a már létezõ ember által írt teszteket próbálták feljavítani.
75\%-ban szintaktikailag helyes javítás történt, 57\%-ban sikeres tesztet generált, a kód lefedettsége pedig 25\%-kal javult. Összesítésben a bemenetkét megadott teszt osztályok 10\%-át javította fel és 
a modell ajánlásai késõbb 73\%-ban elfogadottnak minõsültek a fejlesztõk által.

Alok Mathur és csapata olyan megközelítést alkalmazott a T5 és GPT-3 modellekkel, hogy kizárólag teszt bemeneteket generálnak és/vagy releváns természetes szöveges leírást~\cite{10}.
A fejlesztõk leírnak néhány peremfeltételt vagy követelményeket és a model kimenete releváns tesztesetek lesznek, amik kiértékelhetõk a rendszer megfelelõ végrehajtájtási útvonalaihoz.

Egy nagy nyelvi modellekkel való szoftvertesztelésre specializált kutatási felmérés~\cite{08} alapján senki se gondolkodott még az általunk használt irányban, bemeneti formátum szempontjából.
Kizárólag a hibás függvényt adják át, elõ- vagy utótagot, vagy leírást a javítás, vagy teszt generálásához, de senki sem próbálkozott mind a hibás és a javított kód átadásával a tesztgeneráláshoz. 
A Sugmin Kang és társai által kiállított tanulmányban~\cite{085} szereplõ bemeneti formátum a hiba leírását adja meg a teszteset generáláshoz.

Habár mi is teszt eseteket generálunk, a fentiekkel szemben a mi kutatásunk nem csak egy adott funkcionalitás tesztelését célozza a nagyobb lefedettség vagy a jobb olvashatóság érdekében, 
hanem egy adott sérülékenység elõtte/utána állapotai alapján próbál kimondottan a sérülékenységet bizonyító tesztesetet elõállítani, ami az sérülékeny állapoton hibát jelez, míg a javított változaton sikeresen lefut.



\section{Sérülékenységekhez tartozó tesztesetek}

A mi vizsgálatunkhoz leghasonlóbb irodalom a sérülékenységek és a tesztesetek metszetét tekinti.~\cite{09} az egységteszt generálás szintén úgy történik, hogy a bemenet tartalmazza a régi és új változatát a kódnak,
 de a tényleges generálás instrumentálás és útvonallefedettségen alapul.

%TODO: 12 ???

A mi kutatásunk is ebben a metszetben helyezkedik el, de a fentiekkel szemben mi a napjainkban kibontakozó, 
és egyre biztatóbb eredményeket elérõ nagy nyelvi modelljeit használjuk a sérülékenység bizonyítékául szolgáló teszteset generálására az instrumentáció és/vagy genetikus algoritmusok alkalmazása helyett.


\chapter{Módszertan}
%\addcontentsline{toc}{section}{Módszertan}

A kutatásunk folyamata öt lépésre osztható. Elsõsorban kigyûjtöttünk 20 példát a kiértékeléshez, ezután a sérülékeny metódussal rendelkezõ osztályokat felbontottuk fokális kontextusszeletekre.
Létrehoztunk egy promptot, amelyekbe a kiértékelés során beleágyazódott a megfelelõ szintû kódkontextus. Lefuttattuk a többlépcsõs kiértékelõ szkriptet, végül manuálisan átvizsgáltuk a kiértékelés eredményeit. 

\section{Adatok kigyûjtése}
\label{sec:methodology-data}

A kiértékeléshez valós rendszerekben valaha fennálló sérülékenységeket gyûjtöttünk ki. 
Amire mindenképpen szükségünk volt az adathalmaz kiválasztása során, azok a sérülékeny metódusok, javításuk és egy környezet, amiben ezeket a metódusokat tesztelni tudjuk. 

Ezeknek az igényeknek eleget tett az APR-rel kapcsolatos kutatásokhoz széleskörben használt VUL4J~\cite{vul4j} adatbázis, amely számos tanúsított Java sérülékenységekhez tartalmaz valós példákat. 
Rengeteg hasznos információ áll rendelkezésünkre ezzel az adatbázissal, köztük az egyes projektekben szereplõ sérülékenységi azonosítók, javítás elõtti és utáni állapotok, GitHub commit hivatkozások és 
viszonyítási alapnak a PoV (proof of vulnerability) egységtesztek az egyes sérülékenységekhez. 
Társul hozzá egy Docker környezet is, amely nagyban megkönnyíti a projektek lefuttatását és ellenõrzését. 

Az adatbázisban szerepelnek olyan sebezhetõségek, amely kijavításához egy, vagy több metódus javítása szükséges, ami akár több osztály módosítását is igényelheti.
A modell kontextusból való kifutás veszélyének csökkentéseként úgy döntöttünk, hogy csak olyan példákat használunk a kiértékelés során, amelyekben a sérülékenység javítása csak egyetlen osztályt, metódust érint. 

Hogy minél szélesebb spektrumban mérhessük a GPT egységteszt generálási képességeit, igyekeztünk minél több, különbözõ sérülékenységgel rendelkezõ példát használni. 

\section{Fokális kontextusszintek és a promptolás}
\label{sec:methodology-focal-prompt}

Az egységteszt generálásához, a megfelelõ mértékû kontextus definiálása elengedhetetlen, a természetes szöveg mellé szükségünk van a tesztelendõ metódus mellékelésére.
Ehhez a kigyûjtött példák összes sebezhetõ osztályából kontextusdarabokat~\cite{focal_context} gyártottunk, amelyek segítségével az automatizált kiértékelés során könnyedén szabályozhattuk, hogy mekkora kontextussal szeretnénk az adott 
mérést elvégezni. 

Kisebb adathalmazokon való tesztelések után a szintek elosztásában a következõképp döntöttünk:
\begin{itemize}
\item \textbf{L0}: tartalmazza az osztály csomagdeklarációját, az osztály deklarációját és a sebezhetõ metódust.
\item \textbf{L1}: tartalmazza a \textbf{L0}-ban felsorolt elemeket és az osztály konstruktorainak fejlécét, ha van.
\item \textbf{L2}: tartalmazza a \textbf{L1}-ben felsorolt elemeket és az osztályban deklarált metódusainak fejlécét.
\item \textbf{L3}: tartalmazza a \textbf{L2}-ben felsorolt elemeket és az osztályban deklarált mezõket. 
\end{itemize}

A kiértékelés során minden szintbõl lezajlott egy futtatás.

Ahogy az elõbb is említettem, a generáláshoz megfelelõ méretû és elegendõen specifikus kontextusra van szükségünk. 
Elsõ lépésként promptolási referenciákat gyûjtöttünk elõzetes releváns szakirodalmakból~\cite{08,09}, majd a promptolással való kísérletezés következett.

Igyekeztünk minél optimálisabb és lényegretörõbb bemeneti szöveget definiálni, ezért a kísérleti futtatásokból kinyert tapasztalatok alapján formáltuk meg a végleges promptot.


A hivatalos OpenAI dokumentációja szerint\footnote{\url{https://platform.openai.com/docs/guides/gpt/chat-completions-api}} egy válasz generálása során, ha specifikálunk a GPT-nek saját szerepkört, 
akkor könnyebben megérti a hozzáadott kontextust, amivel szemben áll. Ellenkezõ esetben a generikus "segítõkész asszisztens" szerepet kapja meg.
Ez a mi promptunkban az átadott bemenet elejét képezi.
Ezek után ismertetjük a feldolgozandó bemenet jellemzõit, majd a feladatot, amin a modell dolgozni fog.

A leggyakrabban elõforduló hiba a GPT által generált egységtesztekben, az általa írt kódban használt függvények, osztályok importálásának hiánya.

A kiértékelésre szánt példák jelentõs része elavult Java verzióval kerültek fordításra, ezért többször is elõfordult, hogy olyan kódot generált a modell, ami nem volt kompatibilis ezekkel a változatokkal.
Ezért úgy döntöttünk, hogy külön figyelmeztetjük a modellt a promptolás során ezekre a részletekre.
Az osztály nevek egységessége is problémát okozott az automatikus kiértékelés során, ezért a kiértékelés során ezeknek a formátumát is definiáltuk a promptban.

Ezután következett maga a feldolgozandó bemenet, a forráskód az elõzõ fejezetben említett fokális kontextusként megadva. Elõször a sérülékenységgel rendelkezõ metódus, körítve a kontextusszintnek megfelelõ hozzáadott
adatokkal, ezt követõen pedig a javítást tartalmazó metódus, de ez már a kontextus többi része nélkül, annak érdekében, hogy a feldolgozandó prompt mérete ne legyen feleslegesen túl nagy.

Végezetül érzelmi stimulációt alkalmazunk a modellen, amiben közöljük, hogy a feladat megoldása nagyon fontos számunkra. Ez az eljárás jobb eredményekhez vezet.~\cite{erzelmi_stimulacio}

\newpage

A végsõ prompt, amellyel a kiértékelés összes példája lezajlott a következõképp állt össze:

\begin{lstlisting}[caption={A végleges prompt}, captionpos=b, breaklines=true]
  You are a senior software tester and a cyber security specialist.
  You will be given the source code of a Java class where you will find the context of a vulnerable method before and after the patch.
  Your task is to create a unit test that triggers the vulnerability and fails before the patch and passes after it. The class' name should be the name of the class appended with the string "Test".
  Use simple Java language features in the generated test!

  {focal context of the vulnerable code}

  The method after patching the vulnerability:

  {patched method of vulnerable code}

  It is very important for me, please create the unittest based on your best knowledge in the given context.

\end{lstlisting}

Az automatikus kiértékelés során felvetettük az ötletet, hogy érdemes lenne több iterációt végrehajtani a véletlenszerû eredmények elkerülése, a generálás konzisztenciájának vizsgálata érdekében.
Az iterációk helyett korlátozott számú visszakérdezéses finomhangolás mellett döntöttünk, abban az esetben, ha a generált válasz nem felel meg a megfelelõ szempontok alapján kiállított kritériumoknak.
Ezekhez a visszakérdezésekhez különbözõ promptok társulnak. Mivel a visszakérdezés ugyanabban az üzenetváltási környezetben történik, ezért a modell nem felejti el az elõzõlegesen átadott információkat, így 
ezeknél a promptoknál nem szükséges a szerepkör és egyéb technikai információ ismertetése.

Ebbõl kiindulva csupán egy egyszerû visszajelzést adtunk bemenetként a GPT-nek, az éppen fennálló kritérium megsértésérõl a tesztelés futtatása során keletkezett naplófájl társításával.

Három elfogadást megtagadó helyzet állt fent, amelyekhez társult prompt:

\begin{itemize}
  \item \textbf{BEFORE\_SUCCESS} - A sérülékeny metódus sikeres tesztet produkál.
  \item \textbf{AFTER\_FAILURE} - A javított metódus sikertelen tesztet produkál.
  \item \textbf{ERROR} - A teszt futtatása fordítási hibát okoz.
\end{itemize}


\newpage


\section{Kiértékelõ környezet}
\label{sec:methodology-evalenv}

A kutatás során a legnagyobb szerepet az automatizált kiértékelõnk játszotta.
A generálás a GPT legújabb elérhetõ modelljével történt, a legfrissebb GPT-4 Turbo-t használtuk.
Nagyban megkönnyítette az adathalmazunkon végzett mérések folyamatát, hiszen a projektenként szétbontott kontextusszeletek és a projektek elérési útvonalának segítségével, a GPT API-val való kommunikáción át, 
a generált válasz lefuttatása és az eredmény kiértékelése teljesen automatikus volt. 
Ezen felmérés egy néhány lépcsõs folyamatba foglalható.% A végleges változatunkban minden példa egyesével került feldolgozásra. 

\subsubsection{Kontextus legyártása}

Elsõsorban az elõre definiált fokális kontextusszint megadásával megépítette azt a Java fájlt, 
amely szintaktikailag is helyesen struktúrálva tartalmazta a szintnek megfelelõ mennyiségû adatot az adott sérülékenységrõl.

\subsubsection{Kommunikáció a GPT-vel}
A legyártott Java fájl került átadásra a GPT API-val kommunikáló komponensnek, amely a fentebb kifejtett promptot tette egésszé.
A modellel való kommunikáció során visszakapott válaszból kinyeri a Java kódot, amelyet elment egy fájlba és elhelyezi a projekt tesztkörnyezetébe.

\subsubsection{Futtatások}
A futtatás a VUL4J adatbázishoz járó Docker környezetet inicializálva, mindenféle fordításhoz szükséges kompatibilitási igényt kielégítve történik. 
A csökkentett futtatási idõ érdekében kizárólag azt a tesztet futtatja, amelyet a GPT generált.

A futtatás elõször a projekt sérülékenységgel rendelkezõ változatára fut le, és a tesztelés naplófájlját a szkript eltárolja és felhasználja az adott generálás kiértékelésére.
A sérülékeny változat tesztelésének befejezése után, ugyanez a folyamat lezajlott a javítással rendelkezõ változat esetén is.

Megvizsgálja, hogy az adott teszt sikeresen lefutott-e és amennyiben az aktuális állapotban (sérülékeny vagy javított) nem elvárt értéket kapunk, elkezdõdik a visszakérdezéses generálás. 

A visszakérdezés többször is megtörténhet, egészen addig amíg nem történik három egymást követõ fordítási hiba (ekkor feltételezzük, hogy a modell nem fogja tudni megoldani a szintaktikailag helyes tesztgenerálást), 
vagy öt olyan generálás, ahol nem történt fordítási hiba, de nem az elvárt eredményt kaptuk. Azaz a sérülékeny állapot átment a generált teszten, vagy a javított változat bukott meg.

Fontos megjegyezni, hogy a kiértékelés alatt minden példához kapcsolódó generálás esetében a legjobb generációt vettük figyelembe. Ez csupán annyit jelent, hogy ha egyszer is történt nem fordítási hibás generálás, 
akkor a kiértékelõ azt a naplófájlt külön megtartotta és a végsõ eredményekbe ez az eset került bejegyzésre. 

\subsubsection{Futási eredmények}
Tehát a bejegyzett eredmények példánként két részre oszlanak. Ahogy korábban említettük, a futtatás és tesztelés elõször a sérülékeny változattal történik meg (before patch), majd utána a javítottal (after patch).
Mind a két esethez három lehetséges érték társul.

\begin{itemize}
  \item \textbf{ERROR}: A generált teszt fordítási hibát tartalmaz
  \item \textbf{SUCCESS}: A generált teszt az adott állapotban sikeresen lefutott és átment
  \item \textbf{FAILURE}: A generált teszt az adott állapotban rossz várt értékkel tért vissza
\end{itemize}

A ~\ref{chap:results}. fejezetben tárgyalni fogunk néhány olyan esetrõl, ahol felmerült olyan helyzet, ahol ezek a visszajelzések önmagukban nem tartalmazzák a teljes tényszerû eredményt, 
emiatt is volt fontos a következõ szekcióban tárgyalt emberi felmérés. 

\section{Manuális kiértékelés}
\label{sec:methodology-maneval}

A teljesen automatikus és szigorú validálás mellett gondoskodtunk a szubjektív, emberi kiértékelésérõl is a generált teszteknek.
Az egységtesztek elkészítéséhez egy fejlesztõnek is rengeteg releváns háttérinformációval kell rendelkezzen már ahhoz is, hogy egyáltalán olyan tesztet készítsen egy adott programhoz, ami futtatható.
Ezért döntöttünk úgy, hogy a tesztek hasznosságának felmérése érdekében megtekintjük az egyes tesztek felépítését és kézzel is elbíráljuk szemantikai helyességét.

Két esetre bontottuk a kézi kiértékelés véleményezését:
\begin{itemize}
  \item Szemantikailag rossz
  \item Szemantikailag jó
\end{itemize}

Természetesen a szigorú validáláskor helyes kimenetet produkáló eseteket is ellenõriztük kézzel.

%kiértékelõ környezet:

%-lefuttattuk az extrém menõ evaluáló eszközt, ami 5 lépésbõl validált egy generált tesztet:

%1. megépítette a megfelelõ kontextust

%2. átadta a promptot a kontextussal a gptnek

%3. a visszakapott válaszból kiszedte a java kódot

%4. bevágta dockerbe és lefuttatta a tesztet amit generált a gpt a sebezhetõ metódussal és a javítottal is

%5. a logok alapján értelmezte, hogy sikeresen lefutott e a teszt 

%-kellett egy nagyon jó prompt, ezt kitaláltuk ügyesen

%-a kigyûjtött kontextus darabokból létrehoz egy java fájlt ami tartalmazza a megfelelõ kontextus szintû adatokat

%-gpt4 turbóval végeztük a vizsgálatot, õ képezi a következõ lépést, átadja a promptot és a kontextust neki

%-elmenti a válaszát

%-megfogja a választ és szépen kiszedi belõle a java kódot, amennyiben van és a megfelelõ névvel bemásolja az adatgyûjtés alatt elmentett teszt mappába, ahol kizárólag csak azt a tesztet futtatjuk

%-vul4j dockerbõl lefuttatja a projekt tesztjét és evaluálja a logokat

%-ezek az eredmények nem kõbevésett tények, mert a build környezet minden projektnél más specifikációkkal mûködik, ezért néhány helyen szükséges a kézi felülbírálás

%kézi kiértékelés:

%-a megszületett eredményeket átnézzük

%-a technikai háttérinformációk hiányában elõfordulhat, hogy a generált teszt nem fut, viszont szemantikailag jó

% ide volt a fos1

%fos2

\chapter{Eredmények}
\label{chap:results}
\begin{spacing}{1.4}
A ~\ref{sec:methodology-evalenv}. szakaszban említettük, hogy minden példára, akár több mint négyszer, történt generálás a modell által és mindig az utolsó legjobb eredményt vettük figyelembe. 
A kiértékelés részletes eredményeit a ~\ref{tab:sum}. táblázat ábrázolja. Szintén említésre került, hogy az eredmények automatikus és manuális, kézi validáláson is átestek. 
Összesen 80 darab eredménypár született az automata kiértékelés során, ami magába foglal változó mennyiségû visszakérdezéses generálást is.
\end{spacing}
\input{tbl/table_sum}

\section{Szintaktikai elemzés}
\label{sec:syntax-check}

A szintaktikai elemzés során arra voltunk kíváncsiak, hogy mindenféle emberi beavatkozás nélkül képes-e a GPT olyan egységteszt generálásra, amely univerzálisan megállja a helyét egy tesztkörnyezetben,
annak függvényében, hogy a modell megkapta utasításként, az egyszerû Java nyelvi elemeket használjon a válasz során. Elõfordultak olyan esetek, ahol a futtató környezet extra jelölést igényelt a teszt lefuttatása 
érdekében. Ezen kontextus hiánya miatt voltak olyan generálások, ahol maga a teszt az automatikus felmérés során nem futott le, de a projekt fordítási folyamatába beletartozott.
Az utóbb említett tényezõ alapján az ilyen eseteket is elfogadtuk szintaktikailag helyes eredménynek. 

Néhány futtatásnál, ahol a sérülékeny és javított változat egyaránt \textbf{FAILURE} választ produkált, nem feltétlen csak a teszt eredménye volt hibás. 
Fennállt az esete annak a jelenségnek is, hogy maga a fordítás nem hiúsult meg, de a tesztben használt szimbólumok nem voltak elérhetõk a megfelelõ importálások nélkül, amiket a 
modell esetleg elfelejtett, vagy egyszerûen nem is léteztek.
Ezeket a manuális kiértékelés során ellenõriztük és felülbíráltuk. Az ilyen eset a ~\ref{tab:sum}. eredmények táblázatban piros színnel van jelölve.

\begin{framed}
  \noindent \textbf{RQ1: Hány százalékban kaptunk szintaktikailag helyes kódot?}
  
  \noindent A felülbírált eseteket kivéve a statisztikából, \textbf{L0} és \textbf{L1} fokális kontextussal 11 esetben, azaz 55\%-ban szintaktikailag helyes kódot generált a GPT. 
  Továbbá az \textbf{L2}-vel futó generálás 13, azaz 65\%-os és az \textbf{L3} 10, tehát 50\%-os arányban produkált pozitív eredményt. 
\end{framed}



%- Hány százalékban kaptunk szintaktikailag helyes kódot? kérdés megválaszolása

\section{Szemantikai elemzés}
\label{sec:semantic-check}

A szintaktikai elemzés önmagában nem elég ahhoz, hogy eldöntsük a generált tesztek helyességét.
Ebben a szekcióban kizárólag azokat az eseteket vizsgáljuk, amelyek eleget tettek az automatikus validálás kritériumainak, azaz a javítás elõtti állapotra a teszt elbukott, (\textbf{FAILURE}), a javítás utáni állapot 
során pedig sikeres futás történt (\textbf{SUCCESS}).
Az összképet nézve ez összesen 9 alkalommal (15\%) történt meg.

Ezek a generált tesztek, ha csak egy kicsit is, mindig eltérnek a hivatalos VUL4J adathalmazzal járó, példákban szereplõ egységtesztektõl.
Ez arra enged következtetni, hogy a helyesen megoldott példák valószínûsíthetõen nem szerepeltek ebben a formában a GPT tanítási halmazában, amely tovább erõsíti a született eredmények ígéretességét.  

Az eredmények védelme érdekében a kézi kiértékelés során ellenõriztük, hogy ezek a generálások valóban helyesek-e.

\begin{framed}
  \noindent \textbf{RQ2: Hány százalékban kaptunk szemantikailag is helyes kódot?}
  
  \noindent Összesen 9 (15\%) generált teszt volt szemantikailag is helyes. Fokális kontextusszintek szerint az \textbf{L0}, \textbf{L2} és \textbf{L3} 2 (10\%), az \textbf{L1} érdekes módon 3 (15\%) pozitív eredményt
  produkált. 
\end{framed}


\section{Kontextus hatása a pontosságra}
\label{sec:affect-of-context}

Habár a ~\ref{sec:semantic-check}. szekcióban szereplõ eredmények alapján a különbözõ szintû kontextusokra való futtatás nem mutatott különösebb elváltozást, néhány megállapítás született a kutatás során.
Michele és munkatársai~\cite{focal_context} az esetek közel 40\%-ában pozitív eredményeket tudtak produkálni, 
viszont mindezt egy BART alapú modellen, kódbázisú elõtanítással, amihez tartozott egy teszteset generálási finomhangolás.

A manuális kiértékelés alapján megállapítható, hogy a modell sokkal tudatosabb, kevesebb hibalehetõséggel rendelkezõ tesztesetet ír a konstruktorok felépítésének tudatában.
Például \textbf{L0}-t használva a GPT összekeverte a publikusan elérhetõ Java \textit{FileItem} osztályt a példában szereplõ \textit{DiskFileItem} osztállyal.
A konstruktor ismertetésével az \textbf{L1}-ben már egy szintaktikailag megfelelõ tesztet generált a modell.

\begin{lstlisting}[caption={Az L0-ban szereplõ teszt kódja}, captionpos=b, breaklines=true]
...
  @Before
  public void setUp() {
    factory = new DiskFileItemFactory();
  }
  @Test(expected = IOException.class)
  public void testReadObjectWithInvalidRepositoryPath() throws Exception {
      ...
      File invalidRepository = new File("/some/repository\0");
      diskFileItem.setRepository(invalidRepository);
      ...
  }
\end{lstlisting}
\begin{lstlisting}[caption={Az L1-ben szereplõ teszt kódja}, captionpos=b, breaklines=true]
  ...
  @Before
  public void setUp() {
      // Set up a valid repository directory for DiskFileItem
      repository = new File(TEMP_DIR, "diskFileItemTest");
      repository.mkdir();
  
      diskFileItem = new DiskFileItem(FIELD_NAME, CONTENT_TYPE, IS_FORM_FIELD, FILE_NAME, SIZE_THRESHOLD, repository);
  }
  ...
\end{lstlisting}

\newpage

Az ~\ref{sec:syntax-check}. szakaszban tárgyalt eredmények alapján a legjobban teljesítõ kontextusszint az \textbf{L2} volt, amely 13 szintaktikailag megfelelõ generálást produkált.

\begin{framed}
  \noindent \textbf{RQ3: Hogyan befolyásolja a kontextus a generálás pontosságát?}
  
  \noindent A tesztek szubjektív kiértékelései alapján bizonyos mennyiségû extra kontextus hogyan segít a modellnek a feladat precízebb megoldásában. Az \textbf{L0} kontextusszint használatakor
  9 esetben (45\%) nem ítéltük szemantikailag hasznosnak a tesztet, \textbf{L1} esetén 8 esetben (40\%), \textbf{L2} esetén 5 (25\%), \textbf{L3}-ban pedig 7 alkalommal (35\%).

  \noindent Eredményeink jól mutatják, hogy egy bizonyos szintig látványos javuláshoz vezet a hozzáadott kódkontextus.
   
\end{framed}

\section{A generálás szubjektív hasznossága}

%- a generált tesztek (szubjektívan) használhatók? kérdés megválaszolása
A tesztek szubjektív használhatóságánál a fõbb értékelési szempontok a következõk voltak:

\begin{itemize}
  \item A generált teszt releváns a példában levõ sérülékeny kódhoz és annak javításához.
  \item Azt a metódust teszteli, ami a modell feladataként lett meghatározva.
  \item Legfeljebb minimális emberi finomhangolással (például a megfelelõ csomagok importálásával) használható
  \item Nem próbálja meg felülírni a tesztelendõ metódust saját kóddal
\end{itemize}

%TODO:
%-példa egy nem jó tesztre
%-példa egy jó tesztre

A szubjektív kiértékelés során nem elfogadott példa, az \textbf{L0} futtatás során a \textit{VUL4J-24} példához olyan tesztet generált a modell, 
amelyben már saját maga próbálta meghatározni a tesztelendõ osztály metódusának viselkedését, ahelyett, hogy a teszten javított volna a hiba és az elõtte ismertetett kontextus alapján.
Ebben a jelenségben a visszakérdezéses generálás is szerepet játszik, errõl a ~\ref{sec:misc}. szakaszban fogunk tárgyalni.

Továbbá, néhány esetben a kód értelmezésével is akadtak problémái a modellnek. Az \textbf{L1}-es generálásban a \textit{VUL4J-12} példát félreértette, 
a példában szereplõ javítás egy végtelen ciklus kiküszöbölését tartalmazza, ellenben a teszt egy long típusú számértéket integerre való típuskasztolás segítségével akar összehasonlítani egy másik integerrel.
Azonban ezek sem véletlenszerû utasítások, hiszen relevánsak a promptban specifikált kódhoz, viszont a sérülékenység teszteléséhez nem tesznek eleget.

Rengeteg hasznos teszt került generálásra, erre egy példa az \textbf{L3}-ban található \textit{VUL4J-5} generálása.

\begin{lstlisting}[caption={Az L3 VUL4J-5 példára generált teszteset lényeges részei}, captionpos=b, breaklines=true]
  @Test
  public void testExpandVulnerability() {
      ...
      // Vulnerable entry trying to write outside of target directory
      ArchiveEntry vulnerableEntry = new ArchiveEntry("../outsidetarget.txt", false);
      ...
      try {
          // This should fail before patch and pass after patch
          expander.expand(supplier, writer, targetDirectory);
          fail("The test should throw an IOException before the patch as it attempts to expand outside of the target directory.");
      } catch (IOException e) {
          // Expected exception
          String expectedMessage = "expanding ../outsidetarget.txt would create file outside of " + targetDirectory;
          assertEquals(expectedMessage, e.getMessage());
      }
  }
\end{lstlisting}

Habár szintaktikailag nem megfelelõ a teszt, ennek ellenére kifejezetten jól értelmezte a modell a 
feladatát és valóban letesztelte a javítás jelenlétét. A sérülékeny kódban lehetõség volt egy útvonal átjárás sérülékenység kihasználására, miszerint a "../fájl" bemenet átadása visszalép egy szintet a mappaszerkezetben,
ami már nem biztos, hogy a working directory része, ezzel veszélyeztetve rengeteg olyan fájlt, amihez a szerver környezetén kívül senkinek sem lenne külsõ hozzáférése.

\begin{framed}
  \noindent \textbf{RQ4: Milyen a szubjektív használhatósága a generált teszteknek?}
  
  \noindent A fentebb tárgyalt szempontok alapján a generált tesztek 50\%-át hasznosnak ítéltük. Ezek egy fejlesztõ számára akár egy használható vázat tud biztosítani egy sérülékenységet tanúsító egységteszt
  elkészítésében.

  \noindent Eredményeink jól mutatják, hogy egy bizonyos szintig látványos javuláshoz vezet a hozzáadott kódkontextus.
   
\end{framed}


\section{Egyéb tapasztalatok}
\label{sec:misc}

%- milyen hatással volt a prompt
%\subsubsection{Promptok hatása a generálásra} 

\subsubsection{A visszakérdezés által generálással kapcsolatos észrevételek}
%- hogyan segített a visszakérdezés

Mint már említettük, a megközelítésünk egyik pillére a modelltõl való visszakérdezés volt. Ez számos helyzetben segítette a generálás alakulását, hiszen a modell interaktívan visszanyerte az általa írt kódhoz 
tartozó naplófájl tartalmát is. 
Az \textbf{L2}-ben szereplõ \textit{VUL4J-77} példa, elsõ generálásra \textbf{FAILURE} - \textbf{FAILURE} eredménypárral tért vissza, ezért megtörtént a visszakérdezés.
A visszakapott kód a hiba alapján lett finomhangolva a GPT által, ez végül egy teljes, pozitív eredményt produkált.

\begin{lstlisting}[caption={Az L2 VUL4J-77 példára generált válasz (részlet)}, captionpos=b, breaklines=true]
  I apologize for the confusion. 
  It's important to note that with the SafeConstructor, the YAML parser should not throw a SecurityException but rather a YAMLException, ConstructorException, or another related exception when encountering malicious YAML content since it won't be executing any unsafe operations that could potentially trigger a SecurityException.
  ...
  @Test
    public void testReadYamlTreeVulnerability() {
      ...
      assertTrue("Expected a YAML parser exception due to patched vulnerability",
                       e instanceof org.yaml.snakeyaml.error.YAMLException || // change this if needed
                       e instanceof org.yaml.snakeyaml.constructor.ConstructorException); // change this if needed
    }
    ...
\end{lstlisting}

Néhány esetben azonban a modell teljesen elvesztette a fonalat, és a tesztek finomhangolását olyan irányba vitte, ami nem volt releváns a kódban szereplõ hiba kijavításához.
Az \textbf{L1}-ben futtatott \textit{VUL4J-62} példához elõször létrehozott teszt még nem rendelkezik feladatkörbe nem illõ kód generálással.
Fontos megjegyezni, hogy néhány példán való tesztfuttatáshoz szükséges lett volna, hogy a tesztosztály leszármazzon a TestCase osztályból, különben az ilyen projekteknél használt plugin nem ismerte fel a tesztet.
Ennél a példánál is ez a szituáció állt fenn, ami azt jelenti, hogy a naplófájlok csupán annyi üzenetet tartalmaztak, hogy nem futott le egy teszt sem, így a buildelési folyamat sikeresen lezajlott.
Ezek az esetek mindig \textbf{SUCCESS} - \textbf{SUCCESS} eredménypárt alkottak, ami azt jelenti, hogy megtörtént a \textbf{BEFORE\_SUCCESS} prompt által történõ visszakérdezés.

Ezeknél az eseteknél a GPT csak találgatott és sosem tudta megoldani a tesztek futtatását.


\chapter{Limitációk}
\label{chap:lim}

%-csak egy modellt néztünk, GPT4
A kutatás során fennálló limitációk függvényében elsõsorban megjegyzendõ, hogy csak egyetlen nagy nyelvi modell egységteszt generálási képességeit vizsgáltuk, a GPT-4-ét.
A továbbiakban érdemes lehet más modelleket is vizsgálni, akár olyat is, ami kifejezetten kódspecifikus, például a CodeLlama.
%-nincs elõtanítás / finetuning
Nem alkalmaztunk elõtanítást vagy érdemleges finomhangolást. 
A ~\ref{sec:misc}. szakaszban tárgyalt inkonzisztenciák elkerülése érdekében célszerû lehetne Michele és társai~\cite{focal_context} mintájára egyes modelleket kód alapú, majd tesztgenerálási elõtanításban részesíteni.
%-semmi extra adatot nem tartalmazott a prompt, csak a feladatot és a kódot
A prompt szerkezetileg jól struktúrált volt, ám nem tartalmazott extra adatot és információt a javítás elõsegítéséhez.
Érdemes lehet nagyobb hangsúlyt fektetni a prompt engineering részére is a jövõben, például a CWE információk promptba való integrálásával.

%-kicsi adathalmaz
Habár az általunk használt adathalmaz, a VUL4J~\cite{vul4j} egy gondosan összeválogatott sérülékenységek gyûjteménye, nem szabad eltekintenünk a ténytõl, hogy kézzel lett összeállítva.
Ez csupán annyit jelent, hogy a sebezhetõség teljes spektrumát nem feltétlen tartalmazza.
A jövõbeli kutatás során érdemes lehet nagyobb, szélesebb választékú adathalmazt felhasználni, a széleskörû felmérés érdekében.

%-szubjektív használhatóság
%Figyelembe kell vennünk a manuális kiértékelés során esetlegesen elkövetett emberi hibákat. 
Figyelembe kell vennünk, hogy a szubjektív vélemény, a használhatóság megítélése függ az értékelést elvégzõ személyek tapasztalataitól.
Ezen limitáció csökkentésére a kiértékelésben résztvevõk egymás munkáját az egyes példákhoz kapcsolódó megjegyzéseket értelmezve és elemezve ellenõrizték. 

%-nemdet modell
A GPT nemdeterminisztikus természetû, ezért az eredmények gyártása során sosem kaptunk vissza kétszer ugyanolyan választ egy adott példára.


\chapter{Konklúzió}

%-nem haszontalan ez a cucc, a limitációkban leírt bõvítésekkel csak jobb lehet.
Kutatásunk bemutatja a GPT-4 egységteszt generáló képességeit valós környezetben.
Elõzetes irodalmakkal ellentétben, az általunk alkalmazott módszerben egymás mellé tesszük a sebezhetõ és a javított metódust, amely nagy nyelvi modellekkel történõ munka esetén nem megszokott eljárás.
Eredményeink alapján látható, hogy a nagy nyelvi modellekkel történõ egységtesztek generálása tud hasznos segítséget adni a valós életbeli problémák megoldásához.

Felméréseinkbõl a következõ megállapításokat tehetjük:

\begin{enumerate}
  \item A GPT-4 egységteszt generálási képessége elõtanítás nélkül közel sem tökéletes, de az eredmények alapján ígéretes
  \item Ha nem történik szintaktikailag helyes generálás, jó eséllyel minimális emberi finomhangolással helyes tesztesetet tudunk képezni
  \item A különbözõ mennyiségû információt hordozó kontextusszintek valóban hoznak változást a generálás minõségére
  \item A visszakérdezések megfelelõ mennyiségû információval a hiba megoldásához, inkább a helyes irányba viszik a generálást, mintsem a rosszba  
\end{enumerate}

Összegzésként, a nagy nyelvi modellek által történõ egységteszt generálás egyáltalán nem haszontalan irány, azonban a teljesítmény javításához további kutatások szükségesek.
A ~\ref{chap:lim}. fejezetben felsorolt célok megvalósításával is megkérdõjelezhetetlen a mégnagyobb siker. 

%% Az itrodalomjegyzek keszitheto a BibTeX segedprogrammal:
%\bibliography{diploma}
%\bibliographystyle{plain}

%VAGY "kézzel" a következõ módon:

%\begin{thebibliography}{9}
%10-nél kevesebb hivatkozás esetén

\begin{thebibliography}{99}
% 10-nél több hivatkozás esetén

\addcontentsline{toc}{section}{Irodalomjegyzék}
\bibliographystyle{unsrt}
\bibliography{references}

%Elso szerzok vezetekneve alapjan ábécérendben rendezve.


%folyóirat cikk: szerzok(k), a folyóirat neve kiemelve,
%az evfolyam felkoveren, zarojelben az evszam, vegul az oldalszamok es pont.

\bibitem{cve}
Common Vulnerabilities and Exposures.
\url{https://cve.mitre.org/}, 2023%, 199--224.


\bibitem{cwe}
Common Weakness Enumeration.
\url{https://cwe.mitre.org/}, 2023%, 199--224.


\bibitem{vul4j}
Quang-Cuong Bui, Riccardo Scandariato, and Nicolás E. Díaz Ferreyra.
\emph{Vul4j: A dataset of reproducible Java vulnerabilities geared towards the study of program repair techniques}, 2023%, 199--224.

\bibitem{focal_context}
Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, Neel Sundaresan.
\emph{Unit Test Case Generation with Transformers and Focal Context}, 2021%, 199--224.

\bibitem{01}
Quanjun Zhang, Chunrong Fang, Bowen Yu, Weisong Sun, Tongke Zhang, Zhenyu Chen.
\emph{Pre-trained Model-based Automated Software Vulnerability Repair: How Far are We?}, 2023%, 199--224.

\bibitem{02}
Michael Fu, Chakkrit (Kla) Tantithamthavorn, Van Nguyen, Trung Le.
\emph{ChatGPT for Vulnerability Detection, Classification, and Repair: How Far Are We?}, 2023%, 199--224.

\bibitem{03}
Benjamin Steenhoek, Michelle Tufano, Neel Sundaresan, Alexey Svyatkovskiy.
\emph{Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation}, 2023%, 199--224.


\bibitem{05}
Kamel Alrashedy, Abdullah Aljasser.
\emph{Can LLMs Patch Security Issues?}, 2024%, 199--224.

\bibitem{06}
Mohammed Latif Siddiq, Joanna C. S. Santos, Ridwanul Hasan Tanvir, Noshin Ulfat, Fahmid Al Rifat, Vinícius Carvalho Lopes.
\emph{An Empirical Study of Using Large Language Models for Unit Test Generation}, 2024%, 199--224.

\bibitem{07}
Nadia Alshahwan, Jubin Chheda, Anastasia Finegenova, Beliz Gokkaya, Mark Harman, Inna Harper, Alexandru Marginean, Shubho Sengupta, Eddy Wang.
\emph{Automated Unit Test Improvement using Large Language Models at Meta}, 2024%, 199--224.

\bibitem{08}
Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang.
\emph{Software Testing with Large Language Models: Survey, Landscape, and Vision}, 2024%, 199--224.

\bibitem{085}
Sungmin Kang, Juyeon Yoon, Shin Yoo.
\emph{Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction}, 2023%, 199--224.

\bibitem{09}
Kunal Taneja, Tao Xie.
\emph{DiffGen: Automated Regression Unit-Test Generation}, 2008%, 199--224.

\bibitem{10}
Alok Mathur, Shreyaan Pradhan, Prasoon Soni, Dhruvil Patel, Rajeshkannan Regunathan.
\emph{Automated Test Case Generation Using T5 and GPT-3}, 2023%, 199--224.

\bibitem{11}
Chunqiu Steven Xia, Yuxiang Wei, Lingming Zhang.
\emph{Automated Program Repair in the Era of Large Pre-trained Language Models}, 2023%, 199--224.

\bibitem{12}
Xing Hu, zirui Chen, Xin Xia, Yi Gao, Tongtong Xu, David Lo, Xiaohu Yang
\emph{Exploiting Library Vulnerability via Migration Based Automating Test Generation}, 2023%, 199--224.

\bibitem{erzelmi_stimulacio}
Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie.
\emph{Large language models understand and can be enhanced by emotional stimuli}, 2023%, 199--224.


%könyv (szerzo(k), a könyv neve kiemelve, utana a kiado, a kiado szekhelye, az evszam es pont.)
%\bibitem{Pin}
%J.-E. Pin,
%\emph{Varieties of Formal Languages},
%Plenum Publishing Corp., New York, 1986.





\end{thebibliography}




\end{document}

%fos1
%\chapter{Egyebek}

%\section{Környezetek}
%\begin{tét}
%\label{tét-alap}
%Ez itt egy tétel.
%\end{tét}

%A bizonyítás \begin{proof} és \end{proof} közé kerül:
%\begin{proof}
%Ez pedig a bizonyítása, melyben szerepel egy képlet:
%\begin{equation}
%\begin{split}
%E^{\text{globális}} &= \text{tét}_1\cdot E_1^{\text{elemi}}+\text{tét}_2\cdot
%E_2^{\text{elemi}}+\ldots+\text{tét}_n\cdot E_n^{elemi} \\
%&=E^{\text{elemi}}\left(\text{tét}_1+\text{tét}_2+\ldots+\text{tét}_n\right)\\
%&=E^{\text{elemi}}\cdot\text{össztét}
%\end{split}
%\end{equation}
%A második egyenlõségnél azt használtunk ki, hogy ...

%Ezzel a bizonyítást befejeztük.
%\end{proof}

%\begin{defi}
%\label{def-pelda}
%Ez egy definíció. Számozása a tételekkel együtt történik.
%\end{defi}

%\begin{áll}
%A követekezõ négy állítás egymással ekvivalens:
%\label{áll-ekvivalencia}
%  \begin{itemize}
%  \item[(i)] $M$ és $N$ gyengén ekvivalensek.
%  \item[(ii)] Minden $n$
%  nemnegatív egész számra $|L_{M}\cap \Sigma_{1}^{n}|=|L_{N}\cap \Sigma_{2}^{n}|$ teljesül.
%  \item[(iii)] Minden $n$ nemnegatív egész szám esetén
%   létezik
%  $ \pi_{n}: L_{M}\cap \Sigma_{1}^{n} \rightarrow L_{N}\cap \Sigma_{2}^{n} $ kölcsönösen egyértelmû
%  leképezés.
%  \item[(iv)] Minden nemnegatív $n$-re $x A^{n} y^{T}=x' A'^{n} y'^{T}$.
%  \end{itemize}
%\end{áll}

%\begin{köv}
%  Ez pedig egy következmény.
%\end{köv}

%\begin{pld}
%  Ez lesz a példa, ezt nem szedjük dõlten.
%\end{pld}

%\begin{megj}
%  A fejezetet pedig egy megjegyzés zárja.
%\end{megj}


%\section{valami}

%Ez egy fa:
%\begin{itemize}
%    \item elsõ
%    \item második
%      \subitem elsõ
%      \subitem második
%    \item harmadik
%    \item[$\clubsuit$]  saját jel is alkalmazható
%\end{itemize}
%Ez pedig egy számozott lista:
%\begin{enumerate}
%            \item hétfõ
%            \item kedd
%            \item szerda
%\end{enumerate}

%Oldaltörést is alkalmazhatunk
%\pagebreak

%\section{Egy táblázat és egy ábra}